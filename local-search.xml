<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>RL-0</title>
    <link href="/2024/08/16/RL-0/"/>
    <url>/2024/08/16/RL-0/</url>
    
    <content type="html"><![CDATA[<h1 id="1-什么是强化学习？"><a href="#1-什么是强化学习？" class="headerlink" title="1 什么是强化学习？"></a>1 什么是强化学习？</h1><p>广泛地讲，强化学习是机器通过与环境交互来实现目标的一种计算方法。机器和环境的一轮交互是指，机器在环境的一个状态下做一个动作决策，把这个动作作用到环境当中，这个环境发生相应的改变并且将相应的奖励反馈和下一轮状态传回机器。这种交互是迭代进行的，机器的目标是最大化在多轮交互过程中获得的累积奖励的期望。强化学习用智能体（agent）这个概念来表示做决策的机器。相比于有监督学习中的“模型”，强化学习中的“智能体”强调机器不但可以感知周围的环境信息，还可以通过做决策来直接改变这个环境，而不只是给出一些预测信号。<br>智能体和环境之间具体的交互方式如下图所示。在每一轮交互中，智能体感知到环境目前所处的状态，经过自身的计算给出本轮的动作，将其作用到环境中；环境得到智能体的动作后，产生相应的即时奖励信号并发生相应的状态转移。智能体则在下一轮交互中感知到新的环境状态，依次类推。</p><p><img src="/RL-01.png" alt="RL-01"></p><p>这里，智能体有3种关键要素，即感知、决策和奖励。</p><ul><li>感知。智能体在某种程度上感知环境的状态，从而知道自己所处的现状。例如，下围棋的智能体感知当前的棋盘情况；无人车感知周围道路的车辆、行人和红绿灯等情况；机器狗通过摄像头感知面前的图像，通过脚底的力学传感器来感知地面的摩擦功率和倾斜度等情况。</li><li>智能体根据当前的状态计算出达到目标需要采取的动作的过程叫作决策。例如，针对当前的棋盘决定下一颗落子的位置；针对当前的路况，无人车计算出方向盘的角度和刹车、油门的力度；针对当前收集到的视觉和力觉信号，机器狗给出4条腿的齿轮的角速度。策略是智能体最终体现出的智能形式，是不同智能体之间的核心区别。</li><li>奖励。环境根据状态和智能体采取的动作，产生一个标量信号作为奖励反馈。这个标量信号衡量智能体这一轮动作的好坏。例如，围棋博弈是否胜利；无人车是否安全、平稳且快速地行驶；机器狗是否在前进而没有摔倒。最大化累积奖励期望是智能体提升策略的目标，也是衡量智能体策略好坏的关键指标。<br>从以上分析可以看出，面向决策任务的强化学习和面向预测任务的有监督学习在形式上是有不少区别的。首先，决策任务往往涉及多轮交互，即序贯决策；而预测任务总是单轮的独立任务。如果决策也是单轮的，那么它可以转化为“判别最优动作”的预测任务。其次，因为决策任务是多轮的，智能体就需要在每轮做决策时考虑未来环境相应的改变，所以当前轮带来最大奖励反馈的动作，在长期来看并不一定是最优的。</li></ul><h1 id="2-强化学习的环境"><a href="#2-强化学习的环境" class="headerlink" title="2 强化学习的环境"></a>2 强化学习的环境</h1><p>强化学习的智能体是在和一个动态环境的交互中完成序贯决策的。我们说一个环境是动态的，意思就是它会随着某些因素的变化而不断演变，这在数学和物理中往往用随机过程来刻画。其实，生活中几乎所有的系统都在进行演变，例如一座城市的交通、一片湖中的生态、一场足球比赛、一个星系等。对于一个随机过程，其最关键的要素就是状态以及状态转移的条件概率分布。这就好比一个微粒在水中的布朗运动可以由它的起始位置以及下一刻的位置相对当前位置的条件概率分布来刻画。<br>如果在环境这样一个自身演变的随机过程中加入一个外来的干扰因素，即智能体的动作，那么环境的下一刻状态的概率分布将由当前状态和智能体的动作来共同决定，用最简单的数学公式表示则是<br>$下一状态~P(·|当前状态，智能体的动作)$<br>根据上式可知，智能体决策的动作作用到环境中，使得环境发生相应的状态改变，而智能体接下来则需要在新的状态下进一步给出决策。<br>由此我们看到，与面向决策任务的智能体进行交互的环境是一个动态的随机过程，其未来状态的分布由当前状态和智能体决策的动作来共同决定，并且每一轮状态转移都伴随着两方面的随机性：一是智能体决策的动作的随机性，二是环境基于当前状态和智能体动作来采样下一刻状态的随机性。通过对环境的动态随机过程的刻画，我们能清楚地感受到，在动态随机过程中学习和在一个固定的数据分布下学习是非常不同的。</p><h1 id="3-强化学习的目标"><a href="#3-强化学习的目标" class="headerlink" title="3 强化学习的目标"></a>3 强化学习的目标</h1><p>在上述动态环境下，智能体和环境每次进行交互时，环境会产生相应的奖励信号，其往往由实数标量来表示。这个奖励信号一般是诠释当前状态或动作的好坏的及时反馈信号，好比在玩游戏的过程中某一个操作获得的分数值。整个交互过程的每一轮获得的奖励信号可以进行累加，形成智能体的整体回报（return），好比一盘游戏最后的分数值。根据环境的动态性我们可以知道，即使环境和智能体策略不变，智能体的初始状态也不变，智能体和环境交互产生的结果也很可能是不同的，对应获得的回报也会不同。因此，在强化学习中，我们关注回报的期望，并将其定义为价值（value），这就是强化学习中智能体学习的优化目标。<br>价值的计算有些复杂，因为需要对交互过程中每一轮智能体采取动作的概率分布和环境相应的状态转移的概率分布做积分运算。强化学习和有监督学习的学习目标其实是一致的，即在某个数据分布下优化一个分数值的期望。不过，经过后面的分析我们会发现，强化学习和有监督学习的优化途径是不同的。</p><h1 id="4-强化学习中的数据"><a href="#4-强化学习中的数据" class="headerlink" title="4 强化学习中的数据"></a>4 强化学习中的数据</h1><p>接下来我们从数据层面谈谈有监督学习和强化学习的区别。<br>有监督学习的任务建立在从给定的数据分布中采样得到的训练数据集上，通过优化在训练数据集中设定的目标函数（如最小化预测误差）来找到模型的最优参数。这里，训练数据集背后的数据分布是完全不变的。<br>在强化学习中，数据是在智能体与环境交互的过程中得到的。如果智能体不采取某个决策动作，那么该动作对应的数据就永远无法被观测到，所以当前智能体的训练数据来自之前智能体的决策结果。因此，智能体的策略不同，与环境交互所产生的数据分布就不同，如下图所示。<br><img src="/RL-02.png" alt="RL-02"><br>具体而言，强化学习中有一个关于数据分布的概念，叫作占用度量（occupancy measure），其具体的数学定义和性质会在第3章讨论，在这里我们只做简要的陈述：归一化的占用度量用于衡量在一个智能体决策与一个动态环境的交互过程中，采样到一个具体的状态动作对（state-action pair)的概率分布。<br>占用度量有一个很重要的性质：给定两个策略及其与一个动态环境交互得到的两个占用度量，那么当且仅当这两个占用度量相同时，这两个策略相同。也就是说，如果一个智能体的策略有所改变，那么它和环境交互得到的占用度量也会相应改变。<br>根据占用度量这一重要的性质，我们可以领悟到强化学习本质的思维方式。</p><ul><li>强化学习的策略在训练中会不断更新，其对应的数据分布（即占用度量）也会相应地改变。因此，强化学习的一大难点就在于，智能体看到的数据分布是随着智能体的学习而不断发生改变的。</li><li>由于奖励建立在状态动作对之上，一个策略对应的价值其实就是一个占用度量下对应的奖励的期望，因此寻找最优策略对应着寻找最优占用度量。</li></ul><h1 id="5-强化学习的独特性"><a href="#5-强化学习的独特性" class="headerlink" title="5 强化学习的独特性"></a>5 强化学习的独特性</h1><p>通过前面5节的讲解，读者现在应该已经对强化学习的基本数学概念有了一定的了解。这里我们回过头来再看看一般的有监督学习和强化学习的区别。<br>对于一般的有监督学习任务，我们的目标是找到一个最优的模型函数，使其在训练数据集上最小化一个给定的损失函数。在训练数据独立同分布的假设下，这个优化目标表示最小化模型在整个数据分布上的泛化误差（generalization error），用简要的公式可以概括为：<br>最优模型$&#x3D;\arg\min_\text{模型}\mathbb{E}<em>($特征，标签$)\sim$数据分布[损失函数(标签，模型(特征))]<br>相比之下，强化学习任务的最终优化目标是最大化智能体策略在和动态环境交互过程中的价值。根据第4节的分析，策略的价值可以等价转换成奖励函数在策略的占用度量上的期望，即：<br>$\text{最优策略}&#x3D;\arg\max_\text{策略}\mathbb{E}</em>{(\text{状态,动作})\sim\text{策略的占用度里}}[\text{奖励函数}(\text{状态,动作})]$观察以上两个优化公式，我们可以回顾第3节，总结出两者的相似点和不同点。</p><ul><li>有监督学习和强化学习的优化目标相似，即都是在优化某个数据分布下的一个分数值的期望。</li><li>二者优化的途径是不同的，有监督学习直接通过优化模型对于数据特征的输出来优化目标，即修改目标函数而数据分布不变；强化学习则通过改变策略来调整智能体和环境交互数据的分布，进而优化目标，即修改数据分布而目标函数不变。<br>综上所述，一般有监督学习和强化学习的范式之间的区别为：</li><li>一般的有监督学习关注寻找一个模型，使其在给定数据分布下得到的损失函数的期望最小；</li><li>强化学习关注寻找一个智能体策略，使其在与动态环境交互的过程中产生最优的数据分布，即最大化该分布下一个给定奖励函数的期望。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>强化学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Lineargression</title>
    <link href="/2024/08/16/Lineargression/"/>
    <url>/2024/08/16/Lineargression/</url>
    
    <content type="html"><![CDATA[<h1 id="1-基本形式"><a href="#1-基本形式" class="headerlink" title="1 基本形式"></a>1 基本形式</h1><p>线性模型尝试用一个多个属性的线性组合来进行预测：<br>$f(\boldsymbol{x})&#x3D;w_1x_1+w_2x_2+\ldots+w_dx_d+b$<br>写成：<br>$f(\boldsymbol{x})&#x3D;\boldsymbol{w}^\mathrm{T}\boldsymbol{x}+b$<br>模型的确定取决于$w,b$是否被确定.</p><h1 id="2-线性回归"><a href="#2-线性回归" class="headerlink" title="2 线性回归"></a>2 线性回归</h1><h2 id="2-1单输入"><a href="#2-1单输入" class="headerlink" title="2.1单输入"></a>2.1单输入</h2><p>线性回归要求预测值尽可能的接近真实值.<br>对于离散属性，若输入在时域具有先后关系，可以将其进行编码，转化为连续值：<br>将$n$个属性使用$n$维向量进行热编码，例：“高，中，低”可编码为“(100),(010),(001)”<br>线性回归期望获得如下：<br>$f(x_i)&#x3D;wx_i+b,  f(x_i)\simeq y_i$<br>正如第1节所说，确定$w,b$就能得到预测值；确定它们的关键在于度量预测值与真实值之间的差距.<br>在这里，我们尝试用均方误差(MSE)来对其进行度量，即：<br>$(w^*,b^*)&#x3D;\arg\min_{(w,b)}\sum_{i&#x3D;1}^m\left(f\left(x_i\right)-y_i\right)^2$<br>基于均方误差来进行模型求解的方法称为“最小二乘法”，它意味着找到一条直线，使样本到直线上的欧式距离之和最小.<br>求解出最小值的过程称为模型的最小二乘“参数估计”.对上式求偏导：<br>$\frac{\partial E_{(w,b)}}{\partial w}&#x3D;2\left(w\sum_{i&#x3D;1}^mx_i^2-\sum_{i&#x3D;1}^m\left(y_i-b\right)x_i\right)$<br>$\frac{\partial E_{(w,b)}}{\partial b}&#x3D;2\left(mb-\sum_{i&#x3D;1}^m\left(y_i-wx_i\right)\right)$<br>令偏导为0可得$w,b$最优解的闭式解：<br>$w&#x3D;\frac{\sum_{i&#x3D;1}^my_i(x_i-\bar{x})}{\sum_{i&#x3D;1}^mx_i^2-\frac1m\left(\sum_{i&#x3D;1}^mx_i\right)^2}$<br>$b&#x3D;\frac1m\sum_{i&#x3D;1}^m(y_i-wx_i)$</p><h2 id="2-2多输入"><a href="#2-2多输入" class="headerlink" title="2.2多输入"></a>2.2多输入</h2><p>更一般的情形是，输入样本由多个属性.<br>此时期望获得：<br>$f(x_i)&#x3D;w^{T}x_i+b,  f(x_i)\simeq y_i$<br>称多元线性回归.<br>同样的，利用最小二乘法对参数进行估计.<br>将x扩充为</p><p>$\mathbf{X}&#x3D;\begin{pmatrix}x_{11}&amp;x_{12}&amp;\ldots&amp;x_{1d}&amp;1\x_{21}&amp;x_{22}&amp;\ldots&amp;x_{2d}&amp;1\\vdots&amp;\vdots&amp;\ddots&amp;\vdots&amp;\vdots\x_{m1}&amp;x_{m2}&amp;\ldots&amp;x_{md}&amp;1\end{pmatrix}&#x3D;\begin{pmatrix}\boldsymbol{x}_1^\mathrm{T}&amp;1\\boldsymbol{x}_2^\mathrm{T}&amp;1\\vdots&amp;\vdots\\boldsymbol{x}_m^\mathrm{T}&amp;1\end{pmatrix}$</p><p>将输入写成向量形式，则对于$w$,有：<br>$\hat{\boldsymbol{w}}^{*}&#x3D;\arg\min_{\hat{\boldsymbol{w}}}\left(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{w}}\right)^{\mathrm{T}}\left(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{w}}\right)$<br>求偏导得：<br>$\frac{\partial E_{\hat{\boldsymbol{w}}}}{\partial\hat{\boldsymbol{w}}}&#x3D;2 \mathbf{X}^{\mathrm{T}}\left(\mathbf{X}\hat{\boldsymbol{w}}-\boldsymbol{y}\right)$<br>令上式为0即可得到.</p><p>线性函数虽然简单，但变化丰富，我们可以让预测函数与一个可微调函数$g(·)$相乘，使其可以拟合更多类型的数值：<br>$y&#x3D;g^{-1}(w^Tx+b)$<br>上述模型称广义线性模型，</p><h1 id="3-对数几率回归"><a href="#3-对数几率回归" class="headerlink" title="3 对数几率回归"></a>3 对数几率回归</h1><p>对于二分类任务，将得到的预测值转为0&#x2F;1值，最理想的是“单位阶跃函数”，但是它不连续，不能作为可微调函数.作为替代，使用：<br>$y&#x3D;\frac{1}{1+e^{-z}}$<br>若令z等于$(w^Tx+b)$,再进行变化，得：<br>$ln\frac{y}{1-y}&#x3D;(w^Tx+b)$<br>y和1-y分别是正例和反例的可能性.<br>实际上是使用线性回归模型去逼近真实标记的对数几率.</p><h1 id="4-代码"><a href="#4-代码" class="headerlink" title="4 代码"></a>4 代码</h1><p>(基于sklearn库)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/env python</span><br><br><span class="hljs-comment"># -*- encoding: utf-8 -*-</span><br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string"></span><br><span class="hljs-string">@File    :   linear regression.ipynb</span><br><span class="hljs-string"></span><br><span class="hljs-string">@Time    :   2024/08/15 15:59:55</span><br><span class="hljs-string"></span><br><span class="hljs-string">@Author  :   Neutrin</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment">#this is a simple of linear regression models</span><br><span class="hljs-comment"># here put the import lib</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix, ConfusionMatrixDisplay<br><br><span class="hljs-comment">#读取数据</span><br>data = pd.read_csv(<span class="hljs-string">&#x27;watermelon3_0_Ch.csv&#x27;</span>)<br><br><span class="hljs-comment">#热编码</span><br>data = pd.get_dummies(data)<br><span class="hljs-built_in">print</span>(data.shape)<br><br><span class="hljs-comment">#划分数据集</span><br><br>x_train, x_test, y_train, y_test = train_test_split(data.iloc[:,<span class="hljs-number">0</span>:<span class="hljs-number">20</span>],data.iloc[:,<span class="hljs-number">21</span>],test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">0</span>)<br><br><span class="hljs-comment">#建立模型</span><br>model = LogisticRegression(max_iter=<span class="hljs-number">1000</span>)<br>model.fit(x_train, y_train)<br><br><span class="hljs-comment">#预测</span><br>y_pred = model.predict(x_test)<br><br><span class="hljs-comment">#评估</span><br>score = model.score(x_test, y_test)<br><span class="hljs-built_in">print</span>(score)<br>cm = confusion_matrix(y_test, y_pred)<br><br><span class="hljs-comment"># 归一化混淆矩阵</span><br><br>cm_normalized = cm.astype(<span class="hljs-string">&#x27;float&#x27;</span>) / cm.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)[:, np.newaxis]<br><br><span class="hljs-comment"># 绘制归一化混淆矩阵</span><br><br>disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=model.classes_)<br><br>disp.plot(cmap=plt.cm.Blues)<br><span class="hljs-comment"># 显示图像</span><br>plt.title(<span class="hljs-string">&#x27;Normalized Confusion Matrix&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p>结果如图所示：</p><img src="/2024/08/16/Lineargression/LR.png" class="">]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
