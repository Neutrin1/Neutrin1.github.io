<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>多智能体一致性控制中的事件触发方案</title>
    <link href="/2025/06/04/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E4%B8%80%E8%87%B4%E6%80%A7%E6%8E%A7%E5%88%B6%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6%E8%A7%A6%E5%8F%91%E6%96%B9%E6%A1%88/"/>
    <url>/2025/06/04/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E4%B8%80%E8%87%B4%E6%80%A7%E6%8E%A7%E5%88%B6%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6%E8%A7%A6%E5%8F%91%E6%96%B9%E6%A1%88/</url>
    
    <content type="html"><![CDATA[<p>在这篇文章中，简要讨论一下事件触发机制。<br>参考文献：D. V. Dimarogonas, E. Frazzoli and K. H. Johansson, “Distributed Event-Triggered Control for Multi-Agent Systems,” in <em>IEEE Transactions on Automatic Control</em>, vol. 57, no. 5, pp. 1291-1297, May 2012, doi: 10.1109&#x2F;TAC.2011.2174666.</p><h1 id="1-系统模型"><a href="#1-系统模型" class="headerlink" title="1 系统模型"></a>1 系统模型</h1><p>由 N 个智能体组成的系统，$x_i$ 表示第 i 个智能体。<br>给定一个单积分系统：$\dot x_i&#x3D;u_i$<br>其中，$u_i$ 是每个智能体的控制输入。<br>一致性控制律：$u_i&#x3D;-\sum_{j \in N_i}(x_i-x_j)$<br>对于不考虑干扰的标准系统，其闭环方程为：$\dot x_i&#x3D;-\sum_{j \in N_i}(x_i-x_j)$<br>向量化可以得到：$\dot x &#x3D; -Lx$<br>对于这个系统，它们的一致点是初始状态的平均值：$\frac{1}{N} \sum{x_i(0)}$<br>（注：连通图的 $L$ 秩为 N-1，从 $L$ 行和为 0 及特征值特征向量之间的关系可以得出，元素全相同向量是零特征向量！当系统收敛时，状态变化率归零，也就是 $Lx(t)&#x3D;0$, 说明 $x(t)$ 必须在 $L$ 的零空间中，而这个相等的常数则恰好等于系统初始状态的平均值。）</p><h1 id="2-集中式事件触发方案"><a href="#2-集中式事件触发方案" class="headerlink" title="2 集中式事件触发方案"></a>2 集中式事件触发方案</h1><p>对于每个智能体，可以对其定义一个时变误差向量。<br>指定这样的向量：$e(t)&#x3D;[e_1(t),\dots,e_N(t)]^T$ </p><p>事件触发时间序列可以定义为 $t_0,t_1,\dots$ 在这些时刻，控制律得到更新。</p><p>那么在两次控制更新之间，采用零阶保持方案：$u(t)&#x3D;u_i(t)  \forall t \in[t_i,t_{i+1})$</p><p>鉴于上述定义，状态误差向量被定义为：$e(t)&#x3D;x(t_i)-x(t)\forall t \in[t_i,t_{i+1})$</p><p>在集中式控制方案下，间隔时段内的控制策略为：$u(t)&#x3D;-Lx(t_i)$</p><p>闭环系统由如下给出：$\dot x(t)&#x3D;-Lx(t_i)&#x3D;-L(x(t)+e(t))$</p><p>定义智能体平均状态：$\bar x(t)&#x3D;\frac{1}{N}\sum{x_i(t)}$</p><p>由于给定的图是无向的，得到 $\dot{\bar x}(t)&#x3D;\frac{1}{N}\sum_i{\dot{x_i}}&#x3D;-\frac{1}{N}\sum_i\sum_{j\in N_i}(x_i(t)-x_j(t))-\frac{1}{N}\sum_i\sum_{ i\in N_i}(e_i(t)-e_j(t))&#x3D;0$</p><p>因此：$\bar x(t)&#x3D;\bar x(0)&#x3D;\frac{1}{N}\sum_ix_i(0)\equiv \bar x$</p><p>一个对于此闭环系统的候选输入稳定状态李雅普诺夫函数：<br>$V&#x3D;\frac{1}{2}x^TLx$<br>$\dot V&#x3D;x^TL\dot x&#x3D;-x^TLL(x+e)&#x3D;-||Lx||^2-x^TLLe$</p><p>简单放缩：$\dot V&lt;&#x3D;-||Lx||^2+||Lx||||L||||e||$</p><p>使得 e 满足：$||e||&lt;&#x3D;\sigma \frac{||Lx||}{||L||}$</p><p>使得 $\sigma \in (0,1)$, 得到 $\dot V&lt;&#x3D;(\sigma-1)||Lx||^2$</p><p>事件触发得到确定<br>（注：无向图双重求和会互相抵消。）<br>事件时间间隔 ${t_{k+1}-t_k}$ 其下界隐含地由严格正的时间 $\tau&#x3D;\frac{\sigma}{||L||(1+\sigma)}$ 给出<br>定义：$\frac{||e||}{||Lx||}$ 为误差相对于状态分散程度的比例，对其求导<br>$\frac{d}{dt}\frac{||e||}{||Lx||}&lt;&#x3D;(1+(\frac{||L||||e||}{||Lx||})^2)$<br>定义 $y&#x3D;\frac{||e||}{||Lx||}$, $\dot y&lt;&#x3D;(1+||L||y)^2$<br>因此，y 满足界 $y(t)&lt;&#x3D;\phi(t,\phi_0)$ ，后者是 $\dot \phi &#x3D; (1+||L||\phi)^2$ 在初始条件 $\phi(0,\phi_0)&#x3D;\phi_0$ 下的解</p><p>因此，事件间隔事件下界被时间 $\tau$ 界定，$\tau$ 满足 $\phi(\tau,0)&#x3D;\frac{\sigma}{||L||}$<br>上述微分方程的解为： $\phi (\tau, 0)&#x3D;\frac{\tau}{1-\tau||L||}$<br>得：$\tau&#x3D;\frac{\sigma}{||L||(1+\sigma)}$ </p><p>（注：使用微分方程求出最小增长时间）</p><h1 id="3-分布式事件触发方案"><a href="#3-分布式事件触发方案" class="headerlink" title="3 分布式事件触发方案"></a>3 分布式事件触发方案</h1><p>每个智能体的误差定义：<br>$e_i(t) &#x3D; x_i\left(t_k^i\right) - x_i(t), \quad t \in \left[t_k^i, t_{k+1}^i\right).$</p><p>控制率：<br>$u_i(t) &#x3D; -\sum_{j \in N_i} \left(x_i\left(t_k^i\right) - x_j\left(t_{k’}^j(t)\right)\right)$<br>$x_j(t_{k’}^j(t)) &#x3D; x_j(t) + e_j(t)$</p><p>则：$\dot{x}<em>i(t) &#x3D; -\sum</em>{j \in N_i} \left(x_i(t_k^i) - x_j(t_{k’}^j(t))\right) &#x3D; -\sum_{j \in N_i} \left(x_i(t) - x_j(t)\right) - \sum_{j \in N_i} \left(e_i(t) - e_j(t)\right)$<br>$\dot{x}(t) &#x3D; -L (x (t) + e (t))$</p><p>定义：<br>$z_i(t) &#x3D; \sum_{j \in N_i} (x_i(t) - x_j(t)), \quad i &#x3D; 1, \dots, N.$</p><p>选取：<br>$\dot{V} &#x3D; x^T L \dot{x} &#x3D; -x^T L (Lx + Le) &#x3D; -z^T z - z^T Le.$<br>$\dot{V} &#x3D; -\sum_i z_i^2 - \sum_{i} \sum_{j \in N_i} z_i(e_i - e_j) &#x3D; -\sum_i z_i^2 - \sum_i |N_i| z_i e_i + \sum_i \sum_{j \in N_i} z_i e_j.$</p><p>利用杨不等式：<br>$\dot{V} \leq -\sum_i z_i^2 + \sum_i a |N_i| z_i^2 + \sum_i \frac{1}{2a} |N_i| e_i^2 + \sum_i \sum_{j \in N_i} \frac{1}{2a} e_j^2$</p><p>得到：$\sum_{i} \sum_{j \in N_i} \frac{1}{2 a} e_j^2 &#x3D; \sum_{i} \sum_{j \in N_i} \frac{1}{2 a} e_i^2 &#x3D; \sum_i (1&#x2F;2 a) |N_i| e_i^2$</p><p>因此：$\dot{V} \leq -\sum_i (1 - a |N_i|) z_i^2 + \sum_i (1&#x2F;a) |N_i| e_i^2$</p><p>满足：$e_i^2 \leq \frac{\sigma_i a (1 - a |N_i|)}{|N_i|} z_i^2$</p><p>得到：$\dot{V} \leq \sum_i (\sigma_i - 1)(1 - a |N_i|) z_i^2$</p><p>事件触发条件为：$e_i^2 &#x3D; \frac{\sigma_i a (1 - a |N_i|)}{|N_i|} z_i^2$</p><p>(注：证明方法与集中式类似，不做赘述)</p><p>(注：与集中式控制的关键区别在于状态向量的动态方程)</p>]]></content>
    
    
    <categories>
      
      <category>控制</category>
      
    </categories>
    
    
    <tags>
      
      <tag>多智能体</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>增肌第七周复盘</title>
    <link href="/2025/06/02/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%B8%83%E5%91%A8%E5%A4%8D%E7%9B%98/"/>
    <url>/2025/06/02/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%B8%83%E5%91%A8%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>小结：端午假期一旦多吃了一点就爆了。。。</p><table><thead><tr><th>日期</th><th>体重(kg)</th><th>训练内容</th><th>训练项目</th><th>饮食</th><th>体脂率</th></tr></thead><tbody><tr><td>5月26号</td><td>149.3</td><td>有氧</td><td>练乒乓球2h，俯卧撑60</td><td>鸡胸肉</td><td>17.4</td></tr><tr><td>5月27号</td><td>150.6</td><td>综合训练</td><td>俯卧撑170，10KG哑铃反手划船，正手划船4组，7.5KG哑铃单臂弯举4组，8.5KG哑铃单臂弯举2组，卷腹100</td><td>鸡胸肉</td><td>17.7</td></tr><tr><td>5月28号</td><td>150.3</td><td>有氧，练肩</td><td>练乒乓球2h，10KG哑铃推肩8组，5KG哑铃侧平举4组，7.5KG哑铃直立划船4组，拍腿卷腹120</td><td>鸡胸肉</td><td>17.7</td></tr><tr><td>5月29号</td><td>149.6</td><td>有氧，练腿</td><td>跑步22.5KM，练乒乓球1h，30KG箱内收4组，50KG额外屈4组，65坐姿腿屈伸4组，70KG深蹲4组</td><td>鸡胸肉</td><td>17.5</td></tr><tr><td>5月30号</td><td>149.7</td><td>练胸</td><td>40 45KG拉绳卧推2+2，55KG蝴蝶机夹胸4组，俯卧撑60</td><td>鸡胸肉</td><td>17.5</td></tr><tr><td>5月31号</td><td>152.2</td><td>有氧，练背，练腹</td><td>练乒乓球1h，45 50KG高位下拉2+2，50 55KG划船2+2，铁杆直臂下拉4组，13KG哑铃反手，正手划船4组，8.5KG哑铃单臂弯举4组，卷腹200</td><td>鸡胸肉</td><td>18.2</td></tr><tr><td>6月1号</td><td>152</td><td>练肩</td><td>40 45KG蝴蝶机推肩2+2，35KG左铃推肩4组，10KG哑铃直立划船4组，5KG哑铃侧平举4组，8.5KG哑铃单臂弯举4组，俯卧撑70</td><td>鸡胸肉</td><td>18.2</td></tr></tbody></table><p><img src="/image/weight8.png"></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>健身</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>增肌第六周复盘</title>
    <link href="/2025/05/26/%E5%A2%9E%E8%82%8C%E7%AC%AC%E5%85%AD%E5%91%A8%E5%A4%8D%E7%9B%98/"/>
    <url>/2025/05/26/%E5%A2%9E%E8%82%8C%E7%AC%AC%E5%85%AD%E5%91%A8%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>少碳后，体脂率得到了有效控制。</p><table><thead><tr><th>日期</th><th>体重(kg)</th><th>训练内容</th><th>训练项目</th><th>饮食</th><th>体脂率</th></tr></thead><tbody><tr><td>5月19号</td><td>151</td><td>有氧，练胸，综合训练</td><td>练乒乓球1h, 俯卧撑150个，卷腹200，7.5KG哑铃单臂弯举4组</td><td>鸡胸肉</td><td>17.9</td></tr><tr><td>5月20号</td><td>150.5</td><td>有氧，练背，练腹</td><td>练乒乓球1h, 35KG哑铃4组，55 50 40KG辅助引体1+21 40KG高位下拉4组，40 45K划船2+2</td><td>鸡胸肉</td><td>17.7</td></tr><tr><td>5月21号</td><td>150.7</td><td>有氧</td><td>练乒乓球1h</td><td>鸡胸肉</td><td>17.8</td></tr><tr><td>5月22号</td><td>150.9</td><td>有氧，练肩</td><td>乒乓球比赛14局，10KG哑铃推肩8组，5KG哑铃侧平举8组，10KG哑铃直立划船4组，卷腹200</td><td>鸡胸肉</td><td>17.9</td></tr><tr><td>5月23号</td><td>149.7</td><td>练胸，练腹</td><td>俯卧撑150，卷腹150</td><td>鸡胸肉</td><td>17.5</td></tr><tr><td>5月24号</td><td>148.7</td><td>练背，综合训练</td><td>10KG哑铃反手划船4组，13KG哑铃正手划船4组，7.5KG哑铃单臂举4组，卷腹180，俯卧撑30</td><td>鸡胸肉</td><td>17.2</td></tr><tr><td>5月25号</td><td>148.8</td><td>练肩</td><td>10KG哑铃推肩，5KG侧平举4组</td><td>鸡胸肉</td><td>17.2</td></tr></tbody></table><p><img src="/image/weight7.png"></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>健身</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>增肌第五周复盘</title>
    <link href="/2025/05/19/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%BA%94%E5%91%A8%E5%A4%8D%E7%9B%98/"/>
    <url>/2025/05/19/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%BA%94%E5%91%A8%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>首先，自我检讨。<br>连续两个晚上吃了炒饭，实在有点馋，导致体重爆了。<br>第六周起开始刷体脂，第六周复盘我将把体脂刷到16.5。（没完成就不是本人）</p><table><thead><tr><th>日期</th><th>数值</th><th>训练部位</th><th>训练内容</th><th>饮食</th><th>数值</th></tr></thead><tbody><tr><td>5月12号</td><td>149.2</td><td></td><td>技术性调整</td><td></td><td>17.3</td></tr><tr><td>5月13号</td><td>149.4</td><td>练胸、练腹</td><td>蝴蝶机夹胸50 55KG 1+3，13KG 10KG哑铃卧推2+2，10.5KG哑铃卧推4组，俯卧撑100，卷腹160</td><td>鸡胸肉</td><td>17.4</td></tr><tr><td>5月14号</td><td>151.1</td><td>练背、练腹</td><td>（健身房练）50 55KG高位下拉3+1，50KG划船4组，13KG哑铃反手划船4组，13KG哑铃正手划船4组，卷腹100</td><td>鸡胸肉</td><td>17.9</td></tr><tr><td>5月15号</td><td>152.8</td><td>有氧、练肩、练腹</td><td>练乒乓球2h，35 40KG杠铃推肩3+1，40 45KG蝴蝶机推肩3+1，10.5KG哑铃推肩4组，10.5KG哑铃直立划船4组，7.5KG哑铃单臂弯举4组，卷腹200</td><td>鸡胸肉，炒饭</td><td>18.4</td></tr><tr><td>5月16号</td><td>152.5</td><td>有氧</td><td>练乒乓球2h</td><td>鸡胸肉，炒饭</td><td>18.3</td></tr><tr><td>5月17号</td><td>149.7</td><td>练胸，练腹</td><td>55 60KG蝴蝶机夹胸4组，40 45KG杠铃卧推1+3，10KG哑铃卧推4组，卷腹100</td><td>鸡胸肉</td><td>17.5</td></tr><tr><td>5月18号</td><td>152</td><td>有氧、练腿</td><td>练乒乓球2h，（健身房练）腿部蝴蝶机25KG髋内收4组，40 45KG髋外展2+2，55 60KG坐姿腿屈伸2+2，40 60 70KG深蹲1+2+1</td><td>鸡胸肉</td><td>18.1</td></tr></tbody></table><p><img src="/image/weight6.png"></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>健身</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>增肌第四周复盘</title>
    <link href="/2025/05/12/%E5%A2%9E%E8%82%8C%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%A4%8D%E7%9B%98/"/>
    <url>/2025/05/12/%E5%A2%9E%E8%82%8C%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>本周乒乓球比赛又当陪练又当裁判，实在气血不足了…<br>皮质醇过高每天早上6点多就起来了心脏有点受不了…<br>周日技术性调整，睡个好觉。</p><table><thead><tr><th>日期</th><th>数值</th><th>训练部位</th><th>训练内容</th><th>饮食</th><th>数值</th></tr></thead><tbody><tr><td>5月5号</td><td>150.3</td><td>练胸、练腹</td><td>（健身房练）40KG、45KG杠铃卧推2+2，40KG杠铃上斜卧推4组，45KG蝴蝶机夹胸4组，俯卧撑120，卷腹150，40KG臂力器4组</td><td>香蕉+鸡胸肉</td><td>17.7</td></tr><tr><td>5月6号</td><td>150.4</td><td>练背、练腹</td><td>（健身房练）45KG、50KG高位下拉3+1，40KG、45KG划船2+2组，10.5KG哑铃反手划船4组，10.5KG正手划船4组，卷腹240，靠距俯卧撑30</td><td>鸡胸肉</td><td>17.7</td></tr><tr><td>5月7号</td><td>149.1</td><td>练肩、练腹</td><td>练乒乓球1h，（宿舍练）10.5KG哑铃推肩6组，7.5KG哑铃直立划船4组，5KG哑铃侧平举4组，卷腹200</td><td>鸡胸肉</td><td>17.3</td></tr><tr><td>5月8号</td><td>150.4</td><td>有氧、练手臂、练腹</td><td>户外跑3KM，（宿舍练）8KG哑铃弯举4组，8KG哑铃单臂弯举4组，7.5KG哑铃反向弯举4组，7.5KG哑铃单臂弯举4组，卷腹200</td><td>鸡胸肉</td><td>17.7</td></tr><tr><td>5月9号</td><td>150.8</td><td>练胸、练腹</td><td>练乒乓球2h，（宿舍练）10.5KG哑铃卧推4组，13KG哑铃推4组，俯卧撑130、50，55KG蝴蝶机夹胸3+1组，卷腹200</td><td>鸡胸肉</td><td>17.8</td></tr><tr><td>5月10号</td><td>150.5</td><td>练背、练腹</td><td>练乒乓球1h，（宿舍练）13KG哑铃反手划船4组，13KG哑铃正手划船4组，13KG哑铃单臂划船4组，卷腹230，仰卧抬腿25*4</td><td>鸡胸肉</td><td>17.7</td></tr><tr><td>5月11号</td><td>150.9</td><td>技术性调整</td><td>无</td><td>无</td><td>17.8</td></tr></tbody></table><p><img src="/image/weight5.png"></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>健身</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开源仓库4:CBIS-DDSM数据集预处理方法</title>
    <link href="/2025/05/08/%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%934%E2%80%94%E2%80%94CBIS-DDSM%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/"/>
    <url>/2025/05/08/%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%934%E2%80%94%E2%80%94CBIS-DDSM%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="开源仓库4-😉"><a href="#开源仓库4-😉" class="headerlink" title="开源仓库4 😉"></a>开源仓库4 😉</h1><p>发布了一个关于公开乳腺癌数据集 CBIS-DDSM 的数据处理方法。<br>项目地址：<a href="https://github.com/Neutrin1/CBIS-DDSM-Preprocess">CBIS-DDSM-Preprocess</a></p>]]></content>
    
    
    <categories>
      
      <category>数据科学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机视觉</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LSTM网络</title>
    <link href="/2025/05/06/LSTM%E7%BD%91%E7%BB%9C/"/>
    <url>/2025/05/06/LSTM%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="LSTM网络"><a href="#LSTM网络" class="headerlink" title="LSTM网络"></a>LSTM网络</h1><h2 id="什么是LSTM？"><a href="#什么是LSTM？" class="headerlink" title="什么是LSTM？"></a>什么是LSTM？</h2><p>LSTM（Long Short-Term Memory，长短期记忆网络）是一种特殊的循环神经网络（RNN）结构，由Hochreiter和Schmidhuber在1997年提出，专门设计用来解决传统RNN中的长期依赖问题。简单来说，它能够”记住”长序列中的重要信息，并”遗忘”不重要的信息，从而在处理长序列数据时表现出色。</p><h2 id="LSTM的核心思想"><a href="#LSTM的核心思想" class="headerlink" title="LSTM的核心思想"></a>LSTM的核心思想</h2><p>传统RNN在处理长序列时会遇到梯度消失或梯度爆炸问题，导致无法有效学习长距离依赖关系。LSTM通过引入精心设计的内部结构解决了这一问题。</p><p>想象一下，当你阅读一本小说时，你的大脑会选择性地记住重要情节，而对一些细枝末节则可能会逐渐淡忘。LSTM网络的工作原理与此类似，它通过精心设计的”门”结构来控制信息的流动：</p><p>遗忘门（Forget Gate）：决定哪些旧信息需要丢弃。这个门会输出一个0到1之间的值，0表示”完全遗忘”，1表示”完全保留”。<br>输入门（Input Gate）：决定哪些新信息需要存储到细胞状态中。由两部分组成：sigmoid层决定更新哪些值，tanh层创建新的候选值。<br>细胞状态（Cell State）：贯穿整个网络的记忆通道，允许信息在序列中长期传递。<br>输出门（Output Gate）：决定哪些信息需要输出。根据细胞状态过滤信息，确定下一个隐藏状态。<br>结构图如下所示。<br><img src="/image/LSTM1.jpg"></p><h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p>遗忘阶段：LSTM首先决定从上一状态中丢弃哪些信息。遗忘门接收前一时刻的隐藏状态和当前输入，输出一个0到1之间的向量。</p><p>记忆阶段：接着，LSTM决定要在当前细胞状态中存储哪些新信息。这包括两个步骤：<br>输入门决定更新哪些值<br>创建新的候选值，可能会被添加到细胞状态中</p><p>更新阶段：旧的细胞状态与遗忘门相乘，然后加上输入门与候选值的乘积，完成细胞状态的更新。</p><p>输出阶段：最后，LSTM决定输出什么。输出基于细胞状态，但会经过过滤。先运行sigmoid层确定细胞状态的哪些部分会输出，然后将细胞状态通过tanh处理并与sigmoid输出相乘。</p><h2 id="LSTM的优势"><a href="#LSTM的优势" class="headerlink" title="LSTM的优势"></a>LSTM的优势</h2><p>与传统RNN相比，LSTM具有以下优点：</p><ul><li>能够学习长期依赖关系，避免梯度消失问题</li><li>可以有效处理时序数据中的长距离关系</li><li>对噪声有较强的鲁棒性</li></ul><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>LSTM广泛应用于：</p><ul><li>自然语言处理（文本生成、机器翻译）</li><li>语音识别</li><li>时间序列预测</li><li>异常检测</li></ul><h2 id="简化的LSTM公式"><a href="#简化的LSTM公式" class="headerlink" title="简化的LSTM公式"></a>简化的LSTM公式</h2><p>LSTM的核心计算可以简化为以下几个步骤：</p><p>遗忘门：$$ f_t &#x3D; σ(W_f·[h_{t-1}, x_t] + b_f) $$</p><p>输入门：$$ i_t &#x3D; σ(W_i·[h_{t-1}, x_t] + b_i) $$</p><p>候选记忆：$$ \tilde{C}<em>t &#x3D; tanh(W_C·[h</em>{t-1}, x_t] + b_C) $$</p><p>记忆更新：$$ C_t &#x3D; f_t * C_{t-1} + i_t * C̃_t $$</p><p>输出门：$$ o_t &#x3D; σ(W_o·[h_{t-1}, x_t] + b_o) $$</p><p>隐藏状态：$$ h_t &#x3D; o_t * tanh(C_t) $$</p><p>σ是sigmoid函数，将值压缩到0-1之间</p><p>$tanh$是双曲正切函数，将值压缩到-1到1之间</p><p>表示元素乘法（Hadamard积）</p><p>$W$和$b$是可学习的权重和偏置参数</p><p>$h_{t-1}$是前一时间步的隐藏状态</p><p>$x_t$是当前时间步的输入</p><p>$C_{t-1}$是前一时间步的细胞状态</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开源仓库3:基于卷积神经网络的猫狗大战代码</title>
    <link href="/2025/05/05/%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%933%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E4%BB%A3%E7%A0%81/"/>
    <url>/2025/05/05/%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%933%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h1 id="开源仓库3-🚀"><a href="#开源仓库3-🚀" class="headerlink" title="开源仓库3 🚀"></a>开源仓库3 🚀</h1><p>此仓库内是一个基于卷积神经网络的代码，用于解决kaggle中的猫狗大战问题，内含数据集。<br>项目地址：<a href="https://github.com/Neutrin1/cat-vs-dog">cat-vs-dog</a></p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开源仓库2:基于粒子群算法的简要路径规划</title>
    <link href="/2025/05/05/%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%932%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E8%A6%81%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"/>
    <url>/2025/05/05/%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%932%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E8%A6%81%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/</url>
    
    <content type="html"><![CDATA[<h1 id="开源仓库2-🛸"><a href="#开源仓库2-🛸" class="headerlink" title="开源仓库2 🛸"></a>开源仓库2 🛸</h1><p>一个基于粒子群优化算法的简要路径规划仓库。<br>项目地址：<a href="https://github.com/Neutrin1/PSO-for-path-planning">PSO-for-path-planning</a></p>]]></content>
    
    
    <categories>
      
      <category>优化算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>优化算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开源仓库1:MIMO-OFDM无线通信技术Python实现</title>
    <link href="/2025/05/05/%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%931%E2%80%94%E2%80%94MIMO-OFDM%E6%97%A0%E7%BA%BF%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AFPython%E5%AE%9E%E7%8E%B0/"/>
    <url>/2025/05/05/%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%931%E2%80%94%E2%80%94MIMO-OFDM%E6%97%A0%E7%BA%BF%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AFPython%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="开源仓库1🎇"><a href="#开源仓库1🎇" class="headerlink" title="开源仓库1🎇"></a>开源仓库1🎇</h1><p>本仓库包含了《MIMO-OFDM 无线通信技术》一书中算法和示例的 Python 实现版本。原书主要使用 MATLAB 代码展示多输入多输出 (MIMO) 和正交频分复用 (OFDM) 无线通信系统的关键概念和算法。<br>项目地址：<a href="https://github.com/Neutrin1/MIMO_OFDM-Python-Code">MIMO-OFDM 无线通信技术 Python 实现</a></p>]]></content>
    
    
    <categories>
      
      <category>无线通信</category>
      
    </categories>
    
    
    <tags>
      
      <tag>无线通信</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>增肌第三周复盘</title>
    <link href="/2025/05/04/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%B8%89%E5%91%A8%E5%A4%8D%E7%9B%98/"/>
    <url>/2025/05/04/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%B8%89%E5%91%A8%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>2025年第17周健身运动记录与复盘。<br>周六商务喝酒去了，体重又爆了。<br>乒乓球打得很多，但是为什么体重与体脂在涨？估计五一吃多了…</p><table><thead><tr><th>日期</th><th>体重</th><th>健身项目</th><th>健身记录</th><th>练后餐</th><th>体脂率</th></tr></thead><tbody><tr><td>4月28号</td><td>148.8</td><td>练胸、练腹</td><td>练乒乓球2h，（宿舍练）10KG哑铃推胸8组，俯卧撑110，卷腹200</td><td>鸡胸肉+香蕉</td><td>17.2</td></tr><tr><td>4月29号</td><td>148.9</td><td>练背、练腹</td><td>练乒乓球2.5h，（健身房练）40KG、45KG高位下拉2+2，40KG、45KG划船2+2，25KG拉容侠划船4组，无门袋下拉 4组</td><td>鸡胸肉+香蕉</td><td>17.3</td></tr><tr><td>4月30号</td><td>149.7</td><td>练肩</td><td>练乒乓球2h，20KG哑铃推肩 4组</td><td>鸡胸肉+香蕉</td><td>17.5</td></tr><tr><td>5月1号</td><td>149.1</td><td>练胸、练腹</td><td>练乒乓球2.5h，（健身房练）45KG蝴蝶机夹胸4组，35 40 45KG拉铃卧推2+4+2，俯卧起坐120，俄罗斯转体120</td><td>鸡胸肉+香蕉</td><td>17.3</td></tr><tr><td>5月2号</td><td>149.4</td><td>练背</td><td>练乒乓球2.5h，（宿舍练）10KG哑铃反手划船4组，10KG哑铃正手划船4组</td><td>鸡胸肉+香蕉</td><td>17.4</td></tr><tr><td>5月3号</td><td>150.7</td><td>无</td><td>无</td><td>无</td><td>17.9</td></tr><tr><td>5月4号</td><td>151.5</td><td>练手臂、练腹</td><td>练乒乓球2.5h，（宿舍练）8.25KG哑铃弯举4组，8.25KG哑铃弯举4组，8.25KG哑铃反向弯举4组，7.5KG哑铃单臂弯举4组</td><td>鸡胸肉</td><td>18</td></tr></tbody></table><p><img src="/image/weight4.png"></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>健身</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer</title>
    <link href="/2025/04/29/Transformer/"/>
    <url>/2025/04/29/Transformer/</url>
    
    <content type="html"><![CDATA[<p>Transformer是一种基于注意力机制的编码器-解码器模型；与CNN相比，视觉Transformer在多个基准测试中取得了令人印象深刻的性能改进。</p><h1 id="1-Transformr"><a href="#1-Transformr" class="headerlink" title="1. Transformr"></a>1. Transformr</h1><p>最初的Transformer首先应用于序列到序列自动回归的任务。与先前的序列转导模型相比，这种原始的Transformer继承了编码器-解码器结构，但通过使用multi-head attention机制和point-wise feed-forward网络，完全放弃了递归和卷积。图1展示了带有编码器-解码器架构的整体Transformer模型。具体而言，它由N个连续的编码器模块组成，每个编码器由两个子层组成。<br>1） MHSA层聚合编码器嵌入内的关系；<br>2） 逐位置FFN层提取特征表示。<br><img src="/image/transformer1.jpg"></p><center>图 1</center><p>在自然语言回归模型中，Transformer源于机器翻译任务。给定一个单词序列，Transformer将输入序列矢量化为单词嵌入，添加位置编码，并将生成的向量序列输入编码器。</p><h2 id="编码器："><a href="#编码器：" class="headerlink" title="编码器："></a>编码器：</h2><p>编码器由 N&#x3D;6 一组相同的层组成。每个图层都有两个子图层。第一个是多头自注意力机制，第二个是简单的、位置方向的全连接前馈网络。我们在两个子层中的每一个周围采用残差连接，然后进行层归一化。 即每个子层的输出为$LayerNorm⁢(x+Sublayer⁢(x))$ ，其中$Sublayer⁢(x)$是子层本身实现的函数。为了促进这些残差连接，模型中的所有子层以及嵌入层都会生成dimension$d_dmodel&#x3D;512$的输出。</p><h2 id="译码器："><a href="#译码器：" class="headerlink" title="译码器："></a>译码器：</h2><p>解码器也由 N&#x3D;6 一堆相同的层组成。除了每个编码器层中的两个子层之外，解码器还插入了第三个子层，该子层对编码器堆栈的输出执行多头注意。与编码器类似，我们在每个子层周围采用残差连接，然后进行层归一化。我们还修改了解码器堆栈中的 self-attention 子层，以防止 positions 关注后续位置。这种掩码，再加上输出嵌入向量偏移一个位置的事实，确保对 position i 的预测只能依赖于位置小于 i 的已知输出。</p><h2 id="注意力："><a href="#注意力：" class="headerlink" title="注意力："></a>注意力：</h2><p>注意力函数可以描述为将查询和一组键值对映射到输出，其中查询、键、值和输出都是向量。输出计算为值的加权和，其中分配给每个值的权重由具有相应键的查询的兼容性函数计算。</p><h3 id="缩放点积注意力"><a href="#缩放点积注意力" class="headerlink" title="缩放点积注意力"></a>缩放点积注意力</h3><p>输入包括 查询和键 dimension $d_k$ ，以及 dimension $d_v$ 的值。我们计算包含所有键的查询的点积，将每个键除以$\sqrt{d_k}$ ，并应用 softmax 函数来获取值的权重。结构如图2所示。<br>计算输出矩阵：$Attention(Q,K,V)&#x3D;softmax(\frac{QK^T}{\sqrt{d_k}})V$<br><img src="/image/transformer2.png"></p><center>图 2</center><h2 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h2><p>我们发现，将查询、键和值 h 分别使用不同的学习线性投影到 $d_k$ 和 $d_k$ $d_v$ 维度，而不是使用 $d_model$-dimensional keys、values 和 queries 执行单个注意力函数是有益的。然后，在查询、键和值的每个投影版本上，我们并行执行 attention 函数，产生 $d_v$-dimensional 输出值。这些值被连接起来并再次投影，从而得到最终值，如图3所示。</p><p><img src="/image/transformer3.png"></p><center>图 3</center>多头注意力允许模型共同关注来自不同位置的不同表示子空间的信息。对于单个注意力头，平均会抑制这种情况。<h1 id="2-Vision-Transformer"><a href="#2-Vision-Transformer" class="headerlink" title="2. Vision-Transformer"></a>2. Vision-Transformer</h1><p>Vision Transformer是一种将 Transformer 架构引入计算机视觉领域的模型，用于处理图像分类、目标检测、语义分割等视觉任务。它通过自注意力机制捕捉图像特征间的关系，突破了传统CNN在处理长距离依赖和全局信息时的局限。</p><p><img src="/image/transformer4.png"></p><center>图 4</center>## 图像分块将输入图像划分为多个固定大小的图像块（如 16×16），每个块展平为一维向量，形成序列，使 Transformer 能以处理序列的方式处理图像。<h2 id="线性嵌入"><a href="#线性嵌入" class="headerlink" title="线性嵌入"></a>线性嵌入</h2><p>通过可学习的线性变换（全连接层），将每个图像块向量映射为固定维度的嵌入向量，降低数据维度。</p><h2 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h2><p>引入可学习的一维位置编码或正弦 &#x2F; 余弦固定编码，弥补自注意力机制对顺序不敏感的缺陷，让模型感知图像块的空间位置信息。</p><h2 id="Transformer编码器"><a href="#Transformer编码器" class="headerlink" title="Transformer编码器"></a>Transformer编码器</h2><p>由多个 Transformer 块组成，每个块包含多头自注意力（捕捉不同尺度和语义的依赖关系）和前馈网络（对注意力输出进行非线性变换），通过残差连接和层归一化加速训练。</p><h2 id="分类头"><a href="#分类头" class="headerlink" title="分类头"></a>分类头</h2><p>提取 Transformer 输出中类别嵌入的特征，通过 MLP（多层感知机）映射到具体类别，完成图像分类任务。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>增肌第二周复盘</title>
    <link href="/2025/04/28/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%BA%8C%E5%91%A8%E5%A4%8D%E7%9B%98/"/>
    <url>/2025/04/28/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%BA%8C%E5%91%A8%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>增肌第二周，力量有明显提升，数据有大的波动。<br>周六商务喝酒去了，没有练。<br>下周保持。</p><table><thead><tr><th>日期</th><th>数值</th><th>训练部位</th><th>训练内容</th><th>饮食</th><th>数值</th></tr></thead><tbody><tr><td>4月21日</td><td>149.1</td><td>练胸、练腹</td><td>练乒乓球1.5h；（宿舍练）10KG哑铃推胸10组，早起俯卧撑30，俯卧撑100，40KG臂力器4组，卷腹200</td><td>鸡胸肉+香蕉</td><td>17.9</td></tr><tr><td>4月22日</td><td>148.5</td><td>练背、练腹</td><td>练乒乓球1.5h；（宿舍练）10KG哑铃反手划船4组、正手划船4组、俯身抱拉4组、单边划船4组，卷腹150</td><td>鸡胸肉+香蕉</td><td>17.1</td></tr><tr><td>4月23日</td><td>146.9</td><td>练肩、练腹</td><td>（宿舍练）10KG哑铃推8组，7.5KG哑铃直立划船8组，5KG侧平举4组，卷腹200</td><td>鸡胸肉+香蕉</td><td>16.6</td></tr><tr><td>4月24日</td><td>147.4</td><td>练手臂、练腹</td><td>练乒乓球1h，（宿舍练）5、7.5KG哑单臂铃弯举4组，7.5KG哑铃弯举4组，7.5KG哑铃正手弯举4组，7.5KG哑铃锤式弯举4组</td><td>鸡胸肉+香蕉</td><td>16.8</td></tr><tr><td>4月25日</td><td>147.6</td><td>练胸、练腹</td><td>（健身房练）35KG，40KG斜推上胸2+2，35KG，40KG斜推下胸2+2，蝴蝶机45KG夹胸4组，俯卧撑100，臂力器40KG 4组</td><td>鸡胸肉+香蕉</td><td>16.9</td></tr><tr><td>4月26日</td><td>149.9</td><td>无</td><td>无</td><td>无</td><td>17.6</td></tr><tr><td>4月27号</td><td>149.7</td><td>练肩、练腹</td><td>练乒乓球1h，蝴蝶机40KG推肩4组，15KG杠铃直立划船4组，10KG哑铃推肩8组，俯卧撑50，卷腹200</td><td>鸡胸肉+香蕉</td><td>17.5</td></tr></tbody></table><p><img src="/image/weight3.png"></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>健身</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2023.2~2025.3体重复盘</title>
    <link href="/2025/04/21/2023-2-2025-3%E4%BD%93%E9%87%8D%E5%A4%8D%E7%9B%98/"/>
    <url>/2025/04/21/2023-2-2025-3%E4%BD%93%E9%87%8D%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>记录及复盘一下2023.2~2025.3之间的体重数据。<br><img src="/image/weight1.png"></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>健身、减脂</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>增肌第一周复盘</title>
    <link href="/2025/04/21/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%B8%80%E5%91%A8%E5%A4%8D%E7%9B%98/"/>
    <url>/2025/04/21/%E5%A2%9E%E8%82%8C%E7%AC%AC%E4%B8%80%E5%91%A8%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>2025年第16周健身记录，增肌第一周。<br>由于这周处于轻感冒的亚健康状态，练得没有很猛。</p><table><thead><tr><th>日期</th><th>体重（单位&#x2F;斤）</th><th>健身记录</th><th>健身项目</th><th>练后餐</th></tr></thead><tbody><tr><td>4.14</td><td>149.1</td><td>练胸、练腹（康复训练）</td><td>(宿舍练)俯卧撑50，7.5KG哑铃弯举4组，10KG哑铃弯举4组，仰卧起坐100，卷腹100</td><td>肉干+香蕉</td></tr><tr><td>4.15</td><td>148.9</td><td>练背、练腹（康复训练）</td><td>练乒乓球1h；（健身房练）45KG高位下拉4组，45KG划船4组，坐姿划船20KG4组，杠铃俯身划船30KG4组，仰卧起坐200，卷腹200</td><td>肉干+香蕉</td></tr><tr><td>4.16</td><td>149.1</td><td>练肩、练腹（康复训练）</td><td>（宿舍练）哑铃坐姿推肩7.5KG8组，哑铃侧平举5KG8组，仰卧起坐100，卷腹150</td><td>无</td></tr><tr><td>4.17</td><td>147.3</td><td>练手臂、练腹（康复训练）</td><td>（宿舍练）7.5KG哑铃弯举4组，7.5KG哑铃锤式弯举4组，哑铃正手弯举4组，5KG哑铃单臂弯举4组</td><td>鸡胸肉+香蕉</td></tr><tr><td>4.18</td><td>148.1</td><td>练胸、练腹（康复训练）</td><td>（宿舍练）7.5KG哑铃斜推8组，40KG臂力器4组，俯卧撑50，卷腹120</td><td>鸡胸肉+香蕉</td></tr><tr><td>4.19</td><td>148.6</td><td>练背、练腹</td><td>练乒乓球1h；（宿舍练）9.5KG哑铃俯身划船4组，9.5KG哑铃俯身反向划船4组，7.5KG哑铃上斜划船4组，5KG俯身哑铃侧平举4组</td><td>鸡胸肉+香蕉</td></tr><tr><td>4.20</td><td>149.1</td><td>练肩、练腹</td><td>练乒乓球1.5h；（宿舍练）7.5KG哑铃推肩4组，9.5KG哑铃推肩4组，9.5KG哑铃阿诺德推举4组，5KG哑铃侧平举4组，7.5KG哑铃直立划船4组</td><td>鸡胸肉+香蕉</td></tr></tbody></table><p><img src="/image/weight2.png"></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>健身</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>EfficientNet网络</title>
    <link href="/2025/04/07/EfficientNet%E7%BD%91%E7%BB%9C/"/>
    <url>/2025/04/07/EfficientNet%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="EfficientNet网络"><a href="#EfficientNet网络" class="headerlink" title="EfficientNet网络"></a>EfficientNet网络</h1><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>EfficientNet是由Google研究团队于2019年提出的一种高效卷积神经网络架构。它通过系统地扩展网络宽度、深度和分辨率，在保持较低参数量和计算成本的同时，实现了卓越的性能表现。EfficientNet系列模型在ImageNet等多个图像分类基准测试中刷新了当时的最高精度记录。</p><h2 id="2-核心创新点"><a href="#2-核心创新点" class="headerlink" title="2. 核心创新点"></a>2. 核心创新点</h2><h3 id="2-1-复合缩放方法（Compound-Scaling）"><a href="#2-1-复合缩放方法（Compound-Scaling）" class="headerlink" title="2.1 复合缩放方法（Compound Scaling）"></a>2.1 复合缩放方法（Compound Scaling）</h3><p>EfficientNet的关键创新是提出了复合缩放方法，即同时按照一定比例缩放网络的三个维度：</p><ul><li>深度（Depth）：增加网络层数</li><li>宽度（Width）：增加特征通道数</li><li>分辨率（Resolution）：增加输入图像大小</li></ul><p>不同于传统方法只关注单一维度的缩放，EfficientNet通过数学公式建立了三个维度之间的平衡关系：</p><p>$$d &#x3D; \alpha^\phi, w &#x3D; \beta^\phi, r &#x3D; \gamma^\phi$$</p><p>其中$\phi$是复合系数，而$\alpha, \beta, \gamma$是通过网格搜索确定的常数。</p><h3 id="2-2-基础网络：EfficientNet-B0"><a href="#2-2-基础网络：EfficientNet-B0" class="headerlink" title="2.2 基础网络：EfficientNet-B0"></a>2.2 基础网络：EfficientNet-B0</h3><p>EfficientNet系列的基础模型B0是通过神经架构搜索（NAS）得到的，其核心构建模块是MBConv（Mobile Inverted Bottleneck Convolution）块，这一设计源自MobileNetV2。</p><h2 id="3-网络结构"><a href="#3-网络结构" class="headerlink" title="3. 网络结构"></a>3. 网络结构</h2><p>EfficientNet的基本架构由以下组件构成：</p><ol><li><strong>stem层</strong>：初始卷积层</li><li><strong>多个MBConv块</strong>：主体特征提取部分</li><li><strong>全局池化层</strong>：特征汇聚</li><li><strong>全连接层</strong>：分类头部</li></ol><h3 id="MBConv块结构"><a href="#MBConv块结构" class="headerlink" title="MBConv块结构"></a>MBConv块结构</h3><p><img src="/image/EfficientNet.png"><br>每个MBConv块包含：</p><ul><li>扩张点卷积（1×1卷积）</li><li>深度可分离卷积（Depthwise Separable Convolution）</li><li>压缩点卷积（1×1卷积）</li><li>残差连接（当输入输出尺寸匹配时）</li><li>SE注意力模块（Squeeze-and-Excitation）</li></ul><h2 id="4-EfficientNet系列模型"><a href="#4-EfficientNet系列模型" class="headerlink" title="4. EfficientNet系列模型"></a>4. EfficientNet系列模型</h2><p>从B0到B7系列模型通过应用不同的复合缩放系数$\phi$得到：</p><table><thead><tr><th>模型</th><th>参数量</th><th>Top-1准确率 (%)</th><th>FLOPS</th><th>缩放系数</th></tr></thead><tbody><tr><td>B0</td><td>5.3M</td><td>77.1</td><td>0.39B</td><td>1.0</td></tr><tr><td>B1</td><td>7.8M</td><td>79.1</td><td>0.70B</td><td>1.1</td></tr><tr><td>B2</td><td>9.2M</td><td>80.1</td><td>1.0B</td><td>1.2</td></tr><tr><td>B3</td><td>12M</td><td>81.6</td><td>1.8B</td><td>1.4</td></tr><tr><td>B4</td><td>19M</td><td>82.9</td><td>4.2B</td><td>1.8</td></tr><tr><td>B5</td><td>30M</td><td>83.6</td><td>9.9B</td><td>2.2</td></tr><tr><td>B6</td><td>43M</td><td>84.0</td><td>19B</td><td>2.6</td></tr><tr><td>B7</td><td>66M</td><td>84.3</td><td>37B</td><td>3.1</td></tr></tbody></table><h2 id="5-性能与优势"><a href="#5-性能与优势" class="headerlink" title="5. 性能与优势"></a>5. 性能与优势</h2><ol><li><strong>高效率</strong>：在相同精度下，EfficientNet比其他CNN架构使用更少的参数和计算资源</li><li><strong>可扩展性</strong>：提供了从轻量级到大规模模型的一整套解决方案</li><li><strong>迁移学习能力</strong>：在多个下游任务中表现优异</li></ol><h2 id="6-应用场景"><a href="#6-应用场景" class="headerlink" title="6. 应用场景"></a>6. 应用场景</h2><ul><li>移动设备上的图像分类</li><li>目标检测（如EfficientDet）</li><li>语义分割</li><li>迁移学习基础模型</li></ul><h2 id="7-代码示例"><a href="#7-代码示例" class="headerlink" title="7. 代码示例"></a>7. 代码示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> efficientnet_b0<br><br><span class="hljs-comment"># 加载预训练的EfficientNet-B0模型</span><br>model = efficientnet_b0(pretrained=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 修改分类头以适应自定义类别数</span><br>num_classes = <span class="hljs-number">10</span><br>model.classifier[<span class="hljs-number">1</span>] = nn.Linear(model.classifier[<span class="hljs-number">1</span>].in_features, num_classes)<br><br><span class="hljs-comment"># 模型推理</span><br>x = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    output = model(x)<br><span class="hljs-built_in">print</span>(output.shape)  <span class="hljs-comment"># torch.Size([1, 10])</span><br></code></pre></td></tr></table></figure><h2 id="8-参考文献"><a href="#8-参考文献" class="headerlink" title="8. 参考文献"></a>8. 参考文献</h2><ol><li>Tan, M., &amp; Le, Q. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. In International Conference on Machine Learning (ICML).</li><li>Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., &amp; Chen, L. C. (2018). MobileNetV2: Inverted Residuals and Linear Bottlenecks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>U-net网络</title>
    <link href="/2025/03/28/U-net%E7%BD%91%E7%BB%9C/"/>
    <url>/2025/03/28/U-net%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="U-net网络：医学图像分割的里程碑"><a href="#U-net网络：医学图像分割的里程碑" class="headerlink" title="U-net网络：医学图像分割的里程碑"></a>U-net网络：医学图像分割的里程碑</h1><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>U-net是一种卷积神经网络架构，最早由Olaf Ronneberger、Philipp Fischer和Thomas Brox在2015年提出，用于生物医学图像分割。该网络因其U形结构而得名，已成为医学图像分割领域的基准模型。U-net在训练数据有限的情况下也能获得精确的分割结果，这使其在医学影像分析中特别有价值。</p><h2 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2. 网络结构"></a>2. 网络结构</h2><p>U-net的架构由两部分组成：收缩路径（编码器）和扩展路径（解码器），整体结构呈”U”形。<br><img src="/image/Unet.png"></p><h3 id="2-1-收缩路径（下采样）"><a href="#2-1-收缩路径（下采样）" class="headerlink" title="2.1 收缩路径（下采样）"></a>2.1 收缩路径（下采样）</h3><p>收缩路径遵循典型卷积网络的架构，从左到右依次为：</p><ul><li><strong>初始层</strong>：输入图像首先经过两次3×3卷积操作，每次卷积后接批归一化和ReLU激活函数</li><li><strong>下采样块</strong>：共4个下采样块，每个包含：<ul><li>2×2最大池化（步长为2）进行下采样，将特征图尺寸减半</li><li>两次3×3卷积（无填充），每次卷积后接批归一化和ReLU</li><li>每次下采样后特征通道数翻倍（64→128→256→512→1024）</li></ul></li><li><strong>底部</strong>：位于网络最深处，包含两个3×3卷积层和ReLU激活函数，特征通道数为1024</li></ul><h3 id="2-2-扩展路径（上采样）"><a href="#2-2-扩展路径（上采样）" class="headerlink" title="2.2 扩展路径（上采样）"></a>2.2 扩展路径（上采样）</h3><p>扩展路径包含4个上采样块，每个块包含：</p><ul><li><strong>上采样操作</strong>：使用2×2转置卷积（步长为2）进行上采样，将特征图尺寸扩大一倍</li><li><strong>特征融合</strong>：将上采样的特征与收缩路径对应层的特征图进行拼接（跳跃连接）<ul><li>这些跳跃连接对于恢复分割过程中丢失的空间信息至关重要</li></ul></li><li><strong>特征处理</strong>：拼接后进行两次3×3卷积操作，每次后接批归一化和ReLU</li><li><strong>特征减半</strong>：每次上采样后特征通道数减半（1024→512→256→128→64）</li></ul><h3 id="2-3-最终输出层"><a href="#2-3-最终输出层" class="headerlink" title="2.3 最终输出层"></a>2.3 最终输出层</h3><ul><li>网络最后使用1×1卷积层将特征图映射到所需的类别数量（C个通道）</li><li>对于二分类任务，通常使用sigmoid激活函数</li><li>对于多分类任务，使用softmax激活函数</li><li>输出特征图尺寸与输入图像相同，实现像素级的精确分割</li></ul><h3 id="2-4-尺寸变化说明"><a href="#2-4-尺寸变化说明" class="headerlink" title="2.4 尺寸变化说明"></a>2.4 尺寸变化说明</h3><p>假设输入图像为572×572：</p><ol><li>每次3×3卷积（无填充）会使特征图尺寸减少4个像素</li><li>四次下采样后，特征图尺寸变为28×28</li><li>上采样过程中恢复尺寸，最终输出为388×388</li><li>这种设计使网络能够对边界区域进行更精确的分割</li></ol><h2 id="3-U-net的创新点"><a href="#3-U-net的创新点" class="headerlink" title="3. U-net的创新点"></a>3. U-net的创新点</h2><p>U-net相比传统CNN有几个关键创新：</p><ol><li><strong>对称的U形结构</strong>：使网络能够同时捕获上下文和精确定位</li><li><strong>跳跃连接</strong>：将编码器的特征直接传递给解码器，保留空间信息</li><li><strong>无全连接层</strong>：保留空间信息，可用于任意尺寸的输入</li><li><strong>数据增强策略</strong>：通过弹性形变等技术有效扩充训练样本</li></ol><h2 id="4-应用场景"><a href="#4-应用场景" class="headerlink" title="4. 应用场景"></a>4. 应用场景</h2><p>U-net在医学图像领域有广泛应用：</p><ul><li>细胞分割</li><li>器官及病变区域分割</li><li>血管分割</li><li>肿瘤检测</li><li>眼底图像分析</li></ul><h2 id="5-U-net变种"><a href="#5-U-net变种" class="headerlink" title="5. U-net变种"></a>5. U-net变种</h2><p>随着技术发展，U-net架构衍生出多个变种：</p><ul><li><strong>3D U-net</strong>：扩展到三维数据处理</li><li><strong>V-net</strong>：用于3D医学图像分割，使用残差连接</li><li><strong>Attention U-net</strong>：引入注意力机制改善特征选择</li><li><strong>TransUnet</strong>：结合Transformer和U-net的优势</li></ul><h2 id="6-代码实现"><a href="#6-代码实现" class="headerlink" title="6. 代码实现"></a>6. 代码实现</h2><p>以下是使用PyTorch实现U-net的简化版本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DoubleConv</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.double_conv = nn.Sequential(<br>            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.double_conv(x)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">UNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_channels, n_classes</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 下采样部分</span><br>        <span class="hljs-variable language_">self</span>.inc = DoubleConv(n_channels, <span class="hljs-number">64</span>)<br>        <span class="hljs-variable language_">self</span>.down1 = nn.Sequential(nn.MaxPool2d(<span class="hljs-number">2</span>), DoubleConv(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>))<br>        <span class="hljs-variable language_">self</span>.down2 = nn.Sequential(nn.MaxPool2d(<span class="hljs-number">2</span>), DoubleConv(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>))<br>        <span class="hljs-variable language_">self</span>.down3 = nn.Sequential(nn.MaxPool2d(<span class="hljs-number">2</span>), DoubleConv(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>))<br>        <span class="hljs-variable language_">self</span>.down4 = nn.Sequential(nn.MaxPool2d(<span class="hljs-number">2</span>), DoubleConv(<span class="hljs-number">512</span>, <span class="hljs-number">1024</span>))<br>        <br>        <span class="hljs-comment"># 上采样部分</span><br>        <span class="hljs-variable language_">self</span>.up1 = nn.ConvTranspose2d(<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.conv1 = DoubleConv(<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>)<br>        <span class="hljs-variable language_">self</span>.up2 = nn.ConvTranspose2d(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.conv2 = DoubleConv(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>)<br>        <span class="hljs-variable language_">self</span>.up3 = nn.ConvTranspose2d(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.conv3 = DoubleConv(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>)<br>        <span class="hljs-variable language_">self</span>.up4 = nn.ConvTranspose2d(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.conv4 = DoubleConv(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)<br>        <span class="hljs-variable language_">self</span>.outc = nn.Conv2d(<span class="hljs-number">64</span>, n_classes, kernel_size=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 编码器路径</span><br>        x1 = <span class="hljs-variable language_">self</span>.inc(x)<br>        x2 = <span class="hljs-variable language_">self</span>.down1(x1)<br>        x3 = <span class="hljs-variable language_">self</span>.down2(x2)<br>        x4 = <span class="hljs-variable language_">self</span>.down3(x3)<br>        x5 = <span class="hljs-variable language_">self</span>.down4(x4)<br>        <br>        <span class="hljs-comment"># 解码器路径</span><br>        x = <span class="hljs-variable language_">self</span>.up1(x5)<br>        x = <span class="hljs-variable language_">self</span>.conv1(torch.cat([x4, x], dim=<span class="hljs-number">1</span>))<br>        x = <span class="hljs-variable language_">self</span>.up2(x)<br>        x = <span class="hljs-variable language_">self</span>.conv2(torch.cat([x3, x], dim=<span class="hljs-number">1</span>))<br>        x = <span class="hljs-variable language_">self</span>.up3(x)<br>        x = <span class="hljs-variable language_">self</span>.conv3(torch.cat([x2, x], dim=<span class="hljs-number">1</span>))<br>        x = <span class="hljs-variable language_">self</span>.up4(x)<br>        x = <span class="hljs-variable language_">self</span>.conv4(torch.cat([x1, x], dim=<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.outc(x)<br></code></pre></td></tr></table></figure><h2 id="7-训练技巧"><a href="#7-训练技巧" class="headerlink" title="7. 训练技巧"></a>7. 训练技巧</h2><p>成功训练U-net网络的几个关键点：</p><ol><li><strong>数据增强</strong>：旋转、缩放、弹性变形等</li><li><strong>权重初始化</strong>：使用适当的初始化方法（如He初始化）</li><li><strong>损失函数选择</strong>：常用Dice损失或交叉熵与Dice损失的组合</li><li><strong>学习率策略</strong>：通常采用衰减学习率</li><li><strong>批量归一化</strong>：帮助加速训练和提高稳定性</li></ol><h2 id="8-优缺点分析"><a href="#8-优缺点分析" class="headerlink" title="8. 优缺点分析"></a>8. 优缺点分析</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>在小数据集上表现优异</li><li>结构简单，训练效率高</li><li>可处理任意大小的输入</li><li>分割精度高，特别适合医学图像</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>对全局上下文信息获取有限</li><li>池化操作可能导致细节信息损失</li><li>在类别不平衡数据上需要特殊处理</li><li>原始结构计算量较大</li></ul><h2 id="9-结论"><a href="#9-结论" class="headerlink" title="9. 结论"></a>9. 结论</h2><p>U-net凭借其简洁而强大的设计，已成为医学图像分割任务的基础架构。虽然已有许多改进版本，但其核心思想—结合多尺度特征和保留空间信息的能力—仍然是现代图像分割网络的基石。随着深度学习技术的不断发展，U-net及其变种将继续在医学图像分析领域发挥重要作用。</p><h2 id="10-参考资料"><a href="#10-参考资料" class="headerlink" title="10. 参考资料"></a>10. 参考资料</h2><ol><li>Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation. MICCAI 2015.</li><li>Zhou Z, et al. UNet++: A nested U-Net architecture for medical image segmentation. DLMIA 2018.</li><li>Chen L C, et al. DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs. IEEE TPAMI 2017.</li><li>Isensee F, et al. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature Methods 2021.</li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>卷积神经网络</title>
    <link href="/2025/03/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2025/03/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络-CNN"><a href="#卷积神经网络-CNN" class="headerlink" title="卷积神经网络 (CNN)"></a>卷积神经网络 (CNN)</h1><p>卷积神经网络(Convolutional Neural Network, CNN)是一类特殊的深度神经网络，专为处理具有网格结构的数据而设计，特别是图像数据。自从2012年AlexNet在ImageNet竞赛中取得突破性成功以来，CNN已成为计算机视觉领域的主导技术。</p><h2 id="1-CNN的基本原理"><a href="#1-CNN的基本原理" class="headerlink" title="1. CNN的基本原理"></a>1. CNN的基本原理</h2><p>卷积神经网络的核心思想是通过卷积操作自动学习空间层次特征。与传统的多层感知机(MLP)不同，CNN具有以下特点：</p><ul><li><strong>局部连接</strong>：每个神经元只与输入数据的一个局部区域连接</li><li><strong>权值共享</strong>：同一特征图中的神经元共享相同的权重</li><li><strong>空间下采样</strong>：通过池化操作减少数据维度并提高鲁棒性</li></ul><p>这些特性使CNN在保留空间信息的同时大幅减少了参数数量，提高了计算效率和泛化能力。</p><h2 id="2-CNN的基本组成部分"><a href="#2-CNN的基本组成部分" class="headerlink" title="2. CNN的基本组成部分"></a>2. CNN的基本组成部分</h2><h3 id="2-1-卷积层-Convolutional-Layer"><a href="#2-1-卷积层-Convolutional-Layer" class="headerlink" title="2.1 卷积层(Convolutional Layer)"></a>2.1 卷积层(Convolutional Layer)</h3><p>卷积层是CNN最重要的组成部分，主要通过卷积操作提取输入数据的特征。</p><p>卷积操作过程如下：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">输入<span class="hljs-operator">:</span> 一个尺寸为 <span class="hljs-variable">H</span>×<span class="hljs-variable">W</span>×<span class="hljs-built_in">C</span> 的数据<span class="hljs-punctuation">(</span>高×宽×通道数<span class="hljs-punctuation">)</span><br>卷积核<span class="hljs-operator">:</span> <span class="hljs-built_in">K</span>个尺寸为 <span class="hljs-variable">Kh</span>×<span class="hljs-variable">Kw</span>×<span class="hljs-built_in">C</span> 的过滤器<br>输出<span class="hljs-operator">:</span> 一个尺寸为 <span class="hljs-variable">H</span><span class="hljs-operator">&#x27;</span>×<span class="hljs-variable">W</span><span class="hljs-operator">&#x27;</span>×<span class="hljs-built_in">K</span> 的特征图<br></code></pre></td></tr></table></figure><p>卷积过程示意：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入矩阵(5×5):        卷积核(3×3):<br>┌───┬───┬───┬───┬───┐  ┌───┬───┬───┐<br>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 0 </span>│  │<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 1 </span>│<br>├───┼───┼───┼───┼───┤  ├───┼───┼───┤<br>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 0 </span>│  │<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 0 </span>│<br>├───┼───┼───┼───┼───┤  ├───┼───┼───┤<br>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 1 </span>│  │<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 1 </span>│<br>├───┼───┼───┼───┼───┤  └───┴───┴───┘<br>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 0 </span>│  <br>├───┼───┼───┼───┼───┤  输出矩阵(3×3):<br>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 1 </span>│<span class="hljs-number"> 0 </span>│<span class="hljs-number"> 0 </span>│  ┌───┬───┬───┐<br>└───┴───┴───┴───┴───┘  │<span class="hljs-number"> 4 </span>│<span class="hljs-number"> 3 </span>│<span class="hljs-number"> 4 </span>│<br>                       ├───┼───┼───┤<br>                       │<span class="hljs-number"> 2 </span>│<span class="hljs-number"> 4 </span>│<span class="hljs-number"> 3 </span>│<br>                       ├───┼───┼───┤<br>                       │<span class="hljs-number"> 2 </span>│<span class="hljs-number"> 3 </span>│<span class="hljs-number"> 3 </span>│<br>                       └───┴───┴───┘    <br></code></pre></td></tr></table></figure><p>卷积过程计算示例(左上角):</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span>×<span class="hljs-number">1</span> + <span class="hljs-number">1</span>×<span class="hljs-number">0</span> + <span class="hljs-number">1</span>×<span class="hljs-number">1</span> +<br><span class="hljs-attribute">0</span>×<span class="hljs-number">0</span> + <span class="hljs-number">1</span>×<span class="hljs-number">1</span> + <span class="hljs-number">1</span>×<span class="hljs-number">0</span> +<br><span class="hljs-attribute">0</span>×<span class="hljs-number">1</span> + <span class="hljs-number">0</span>×<span class="hljs-number">0</span> + <span class="hljs-number">1</span>×<span class="hljs-number">1</span> = <span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><p>卷积核在原始图像上滑动，每个位置执行”乘积求和”操作。卷积过程自动提取特征，如边缘、纹理和形状。不同的卷积核可以检测不同的特征模式，通过学习这些卷积核的权重，CNN能够适应各种视觉识别任务。</p><p>卷积的数学表示：</p><p>$$F(i,j) &#x3D; \sum_{m&#x3D;0}^{k_h-1} \sum_{n&#x3D;0}^{k_w-1} I(i+m, j+n) \cdot K(m,n)$$</p><p>其中$F$是输出特征图，$I$是输入图像，$K$是卷积核。</p><h3 id="2-2-激活函数层"><a href="#2-2-激活函数层" class="headerlink" title="2.2 激活函数层"></a>2.2 激活函数层</h3><p>卷积层之后通常跟随一个非线性激活函数，常用的有：</p><ul><li><strong>ReLU (Rectified Linear Unit)</strong>: $f(x) &#x3D; \max(0, x)$</li><li><strong>Leaky ReLU</strong>: $f(x) &#x3D; \max(0.01x, x)$</li><li><strong>ELU (Exponential Linear Unit)</strong>: $f(x) &#x3D; \begin{cases} x, &amp; \text{if } x &gt; 0 \ \alpha(e^x - 1), &amp; \text{if } x \leq 0 \end{cases}$</li></ul><p>激活函数的引入为网络带来非线性，提高了模型的表达能力。</p><h3 id="2-3-池化层-Pooling-Layer"><a href="#2-3-池化层-Pooling-Layer" class="headerlink" title="2.3 池化层(Pooling Layer)"></a>2.3 池化层(Pooling Layer)</h3><p>池化层的主要功能是减少特征图的空间尺寸，降低计算复杂度，同时提高一定的位移不变性。常见的池化操作有：</p><ul><li><strong>最大池化(Max Pooling)</strong>: 取窗口内的最大值</li><li><strong>平均池化(Average Pooling)</strong>: 计算窗口内像素的平均值</li></ul><h3 id="2-4-全连接层-Fully-Connected-Layer"><a href="#2-4-全连接层-Fully-Connected-Layer" class="headerlink" title="2.4 全连接层(Fully Connected Layer)"></a>2.4 全连接层(Fully Connected Layer)</h3><p>在经过多个卷积和池化层后，特征图被展平为一维向量，然后通过全连接层进行分类或回归。这与传统神经网络的操作类似，每个神经元与前一层的所有神经元相连。</p><h2 id="3-经典CNN架构"><a href="#3-经典CNN架构" class="headerlink" title="3. 经典CNN架构"></a>3. 经典CNN架构</h2><h3 id="3-1-LeNet-5"><a href="#3-1-LeNet-5" class="headerlink" title="3.1 LeNet-5"></a>3.1 LeNet-5</h3><p>由Yann LeCun在1998年提出，是最早的CNN架构之一，用于手写数字识别。</p><p>结构：</p><ul><li>输入: 32×32 灰度图像</li><li>两个卷积层和池化层的组合</li><li>三个全连接层</li></ul><h3 id="3-2-AlexNet"><a href="#3-2-AlexNet" class="headerlink" title="3.2 AlexNet"></a>3.2 AlexNet</h3><p>2012年ImageNet竞赛冠军，标志着深度学习时代的到来。</p><p>主要创新：</p><ul><li>使用ReLU激活函数</li><li>使用Dropout防止过拟合</li><li>使用数据增强技术</li><li>在GPU上进行训练</li></ul><h3 id="3-3-VGG"><a href="#3-3-VGG" class="headerlink" title="3.3 VGG"></a>3.3 VGG</h3><p>由牛津大学提出，以简洁的网络结构著称。</p><p>特点：</p><ul><li>使用3×3的小卷积核</li><li>网络深度达到16-19层</li><li>结构规整，便于理解与修改</li></ul><h3 id="3-4-GoogLeNet-Inception"><a href="#3-4-GoogLeNet-Inception" class="headerlink" title="3.4 GoogLeNet(Inception)"></a>3.4 GoogLeNet(Inception)</h3><p>谷歌提出的网络架构，引入了Inception模块。</p><p>特点：</p><ul><li>使用1×1卷积减少计算量</li><li>并行使用多种尺寸的卷积核</li><li>中间层添加辅助分类器</li></ul><h3 id="3-5-ResNet"><a href="#3-5-ResNet" class="headerlink" title="3.5 ResNet"></a>3.5 ResNet</h3><p>微软研究院提出的残差网络，通过残差连接解决了深层网络的梯度消失问题。</p><p>残差块结构：</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">x ---&gt; Conv ---&gt; BN ---&gt; ReLU ---&gt; Conv ---&gt; BN ---&gt;+---&gt; ReLU ---&gt; output<br><span class="hljs-section">|                                                    ^</span><br><span class="hljs-section">+----------------------------------------------------+</span><br></code></pre></td></tr></table></figure><h2 id="4-CNN的简单实现"><a href="#4-CNN的简单实现" class="headerlink" title="4. CNN的简单实现"></a>4. CNN的简单实现</h2><p>下面是一个使用PyTorch实现的简单卷积神经网络示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><br><span class="hljs-comment"># 定义CNN模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleCNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SimpleCNN, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-comment"># 第一个卷积层，输入通道1，输出通道32，卷积核大小3x3</span><br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 第二个卷积层，输入通道32，输出通道64，卷积核大小3x3</span><br>        <span class="hljs-variable language_">self</span>.conv2 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 池化层</span><br>        <span class="hljs-variable language_">self</span>.pool = nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 全连接层</span><br>        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(<span class="hljs-number">64</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">128</span>)<br>        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)<br>        <span class="hljs-variable language_">self</span>.dropout = nn.Dropout(<span class="hljs-number">0.25</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 第一个卷积层 + 激活函数 + 池化</span><br>        x = F.relu(<span class="hljs-variable language_">self</span>.conv1(x))<br>        x = <span class="hljs-variable language_">self</span>.pool(x)<br>        <span class="hljs-comment"># 第二个卷积层 + 激活函数 + 池化</span><br>        x = F.relu(<span class="hljs-variable language_">self</span>.conv2(x))<br>        x = <span class="hljs-variable language_">self</span>.pool(x)<br>        <span class="hljs-comment"># 展平</span><br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">64</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>)<br>        <span class="hljs-comment"># 全连接层</span><br>        x = F.relu(<span class="hljs-variable language_">self</span>.fc1(x))<br>        x = <span class="hljs-variable language_">self</span>.dropout(x)<br>        x = <span class="hljs-variable language_">self</span>.fc2(x)<br>        <span class="hljs-keyword">return</span> F.log_softmax(x, dim=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 训练函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>(<span class="hljs-params">model, device, train_loader, optimizer, epoch</span>):<br>    model.train()<br>    <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        data, target = data.to(device), target.to(device)<br>        optimizer.zero_grad()<br>        output = model(data)<br>        loss = F.nll_loss(output, target)<br>        loss.backward()<br>        optimizer.step()<br>        <span class="hljs-keyword">if</span> batch_idx % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Train Epoch: <span class="hljs-subst">&#123;epoch&#125;</span> [<span class="hljs-subst">&#123;batch_idx * <span class="hljs-built_in">len</span>(data)&#125;</span>/<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(train_loader.dataset)&#125;</span>]\tLoss: <span class="hljs-subst">&#123;loss.item():<span class="hljs-number">.6</span>f&#125;</span>&#x27;</span>)<br><br><span class="hljs-comment"># 测试函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_model</span>(<span class="hljs-params">model, device, test_loader</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_loader:<br>            data, target = data.to(device), target.to(device)<br>            output = model(data)<br>            test_loss += F.nll_loss(output, target, reduction=<span class="hljs-string">&#x27;sum&#x27;</span>).item()<br>            pred = output.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>            correct += pred.eq(target.view_as(pred)).<span class="hljs-built_in">sum</span>().item()<br>    <br>    test_loss /= <span class="hljs-built_in">len</span>(test_loader.dataset)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;\nTest set: Average loss: <span class="hljs-subst">&#123;test_loss:<span class="hljs-number">.4</span>f&#125;</span>, Accuracy: <span class="hljs-subst">&#123;correct&#125;</span>/<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(test_loader.dataset)&#125;</span> (<span class="hljs-subst">&#123;<span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_loader.dataset):<span class="hljs-number">.2</span>f&#125;</span>%)\n&#x27;</span>)<br><br><span class="hljs-comment"># 主函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-comment"># 检查是否有可用的GPU</span><br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    <br>    <span class="hljs-comment"># 准备数据</span><br>    transform = transforms.Compose([<br>        transforms.ToTensor(),<br>        transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>    ])<br>    <br>    <span class="hljs-comment"># 加载MNIST数据集</span><br>    train_dataset = datasets.MNIST(<span class="hljs-string">&#x27;../data&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>    test_dataset = datasets.MNIST(<span class="hljs-string">&#x27;../data&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=transform)<br>    <br>    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>)<br>    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=<span class="hljs-number">1000</span>)<br>    <br>    <span class="hljs-comment"># 创建模型</span><br>    model = SimpleCNN().to(device)<br>    optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>)<br>    <br>    <span class="hljs-comment"># 训练和测试模型</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>):<br>        train_model(model, device, train_loader, optimizer, epoch)<br>        test_model(model, device, test_loader)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main()<br></code></pre></td></tr></table></figure><p>这个简单的CNN实现可用于MNIST手写数字识别，包含了两个卷积层、两个池化层和两个全连接层。模型结构简洁，易于理解，是入门CNN的理想示例。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>多层感知机</title>
    <link href="/2025/03/27/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    <url>/2025/03/27/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="1-多层感知机-MLP-简介"><a href="#1-多层感知机-MLP-简介" class="headerlink" title="1. 多层感知机(MLP)简介"></a>1. 多层感知机(MLP)简介</h1><p>多层感知机是一种前馈式人工神经网络，是深度学习领域中最基础但功能强大的模型之一。与单层感知机相比，多层感知机能够学习并解决非线性问题，这使其成为现代神经网络架构的基石。</p><h2 id="1-1-原理与结构"><a href="#1-1-原理与结构" class="headerlink" title="1.1 原理与结构"></a>1.1 原理与结构</h2><p>多层感知机由三类层组成：</p><ul><li><strong>输入层</strong>：接收外部数据，每个节点对应一个输入特征</li><li><strong>隐藏层</strong>：一个或多个中间处理层，执行非线性变换，提取特征表示</li><li><strong>输出层</strong>：产生最终预测结果，节点数通常与任务类别数量相关</li></ul><p>每层由多个神经元组成，相邻层的神经元之间全连接。数学上，MLP可表示为：</p><p>$$h^{(1)} &#x3D; \sigma(W^{(1)}x + b^{(1)})$$<br>$$h^{(2)} &#x3D; \sigma(W^{(2)}h^{(1)} + b^{(2)})$$<br>$$\ldots$$<br>$$\hat{y} &#x3D; \sigma(W^{(L)}h^{(L-1)} + b^{(L)})$$</p><p>其中，$\sigma$是激活函数(如ReLU、Sigmoid等)，$W$是权重矩阵，$b$是偏置向量。</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>激活函数引入非线性变换，常用的激活函数包括：</p><ul><li><strong>ReLU</strong>: $f(x) &#x3D; \max(0, x)$，计算高效，有效缓解梯度消失问题</li><li><strong>Sigmoid</strong>: $f(x) &#x3D; \frac{1}{1 + e^{-x}}$，输出范围(0,1)，适合二分类问题</li><li><strong>Tanh</strong>: $f(x) &#x3D; \frac{e^x - e^{-x}}{e^x + e^{-x}}$，输出范围(-1,1)，中心对称特性好</li></ul><h2 id="1-2-训练过程"><a href="#1-2-训练过程" class="headerlink" title="1.2 训练过程"></a>1.2 训练过程</h2><p>MLP通过反向传播算法训练：</p><ol><li><strong>前向传播</strong>：输入数据通过网络，计算预测输出</li><li><strong>计算损失</strong>：根据预测值和实际值计算损失函数值（如交叉熵损失、均方误差等）</li><li><strong>反向传播</strong>：计算损失函数对各参数的梯度，使用链式法则传递误差</li><li><strong>参数更新</strong>：使用优化算法（如梯度下降法、Adam等）更新参数</li></ol><h3 id="a-常用损失函数"><a href="#a-常用损失函数" class="headerlink" title="a)常用损失函数"></a>a)常用损失函数</h3><ul><li>**均方误差(MSE)**：回归问题常用，$L &#x3D; \frac{1}{n}\sum_{i&#x3D;1}^{n}(y_i - \hat{y}_i)^2$</li><li><strong>交叉熵损失</strong>：分类问题常用，$L &#x3D; -\sum_{i&#x3D;1}^{n} y_i\log(\hat{y}_i)$</li></ul><h3 id="b-优化算法"><a href="#b-优化算法" class="headerlink" title="b)优化算法"></a>b)优化算法</h3><ul><li>**随机梯度下降(SGD)**：每次使用一小批数据更新参数</li><li><strong>Adam</strong>：结合动量和自适应学习率的优化方法</li><li><strong>RMSprop</strong>：自适应调整不同参数的学习率</li></ul><h2 id="1-3-应用场景"><a href="#1-3-应用场景" class="headerlink" title="1.3 应用场景"></a>1.3 应用场景</h2><p>MLP广泛应用于：</p><ul><li><strong>图像识别</strong>：手写数字识别、简单物体分类</li><li><strong>语音识别</strong>：语音特征提取与模式匹配</li><li><strong>自然语言处理</strong>：文本分类、情感分析</li><li><strong>金融预测</strong>：股票价</li></ul><h2 id="实现示例"><a href="#实现示例" class="headerlink" title="实现示例"></a>实现示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(MLP, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.layer1 = nn.Linear(input_size, hidden_size)<br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU()<br>        <span class="hljs-variable language_">self</span>.layer2 = nn.Linear(hidden_size, output_size)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = <span class="hljs-variable language_">self</span>.layer1(x)<br>        out = <span class="hljs-variable language_">self</span>.relu(out)<br>        out = <span class="hljs-variable language_">self</span>.layer2(out)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>K邻近法</title>
    <link href="/2025/03/25/K%E9%82%BB%E8%BF%91%E6%B3%95/"/>
    <url>/2025/03/25/K%E9%82%BB%E8%BF%91%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>kNN是一种基本分类与回归方法，这里讨论分类问题的KNN方法。kNN假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其 $k$ 个最近邻的训练实例的类别，通过多数表决等方式进行预测。kNN利用训练数据集对特征向量空间进行划分，并作为其分类的”模型”。三个基本要素是k值的选择、距离度量以及分类决策规则。</p><h1 id="2-k邻近算法-简洁版"><a href="#2-k邻近算法-简洁版" class="headerlink" title="2. k邻近算法(简洁版)"></a>2. k邻近算法(简洁版)</h1><h2 id="2-1算法"><a href="#2-1算法" class="headerlink" title="2.1算法"></a>2.1算法</h2><p>(1)根据给定的距离度量，在训练集T中找出与 $x_i$ 最近邻的 $k$ 个点，涵盖这 $k$ 个点的邻域记作 $N_k(x)$.</p><p>(2)在 $N_k(x)$中根据分类决策规则(如多数表决)决定 $x$ 的类别 $y$：</p><p>$$y &#x3D; \arg \max_{c_j} \sum_{x_i \in N_k(x)} I(y_i &#x3D; c_j), \quad i &#x3D; 1, 2, \dots, N; \quad j &#x3D; 1, 2, \dots, K$$</p><p>其中，$I$ 为指示函数。<br>k近邻法的特殊情况是$k$ &#x3D;1的情形，称为最近邻算法。<br>没有显式的学习过程。</p><h2 id="2-2模型"><a href="#2-2模型" class="headerlink" title="2.2模型"></a>2.2模型</h2><p>当训练集、距离度量、$k$ 值及分类决策规则确定后，对于一个新的输入实例，它所属的类唯一地确定。特征空间中，对于每个训练点 $x_i$，距离该点比其他点更近的所有点组成一个区域，叫做单元；每个训练实例点拥有一个单元，所有训练实例点的单元构成对特征空间的一个划分。最邻近法将实例 $x_i$ 的类 $y_i$ 作为其单元中所有点的类标记。<br><img src="/image/knn1.png"></p><h3 id="a-距离度量"><a href="#a-距离度量" class="headerlink" title="a)距离度量"></a>a)距离度量</h3><p>特征空间中两个实例点的距离是两个实例点相似程度的反映。kNN模型的特征空间一般是n维实数向量空间$R^n$。使用的距离是欧氏距离，也可以是其它距离。</p><h3 id="b-k值的选择"><a href="#b-k值的选择" class="headerlink" title="b)k值的选择"></a>b)k值的选择</h3><p>k值的选择会对k近邻法的结果产生重大影响。</p><p>如果选择较小的 $k$ 值，就相当于用较小的邻域中的训练实例进行预测，”学习”的近似误差（approximation error）会减小，只有与输入实例较近的（相似的）训练实例才会对预测结果起作用。但缺点是”学习”的估计误差（estimation error）会增大，预测结果会对近邻的实例点非常敏感。如果邻近的实例点恰巧是噪声，预测就会出错。换句话说， $k$ 值的减小就意味着整体模型变得复杂，容易发生过拟合。</p><p>如果选择较大的 $k$ 值，就相当于用较大邻域中的训练实例进行预测。其优点是可以减少学习的估计误差。但缺点是学习的近似误差会增大。这时与输入实例较远的（不相似的）训练实例也会对预测起作用，使预测发生错误。k值的增大就意味着整体的模型变得简单。</p><p>如果 $k&#x3D;N$，那么无论输入实例是什么，都将简单地预测它属于在训练实例中最多的类。这时，模型过于简单，完全忽略训练实例中的大量有用信息，是不可取的。<br>在应用中，k值一般取一个比较小的数值。通常采用交叉验证法来选取最优的k值。</p><h3 id="c-分类决策规则"><a href="#c-分类决策规则" class="headerlink" title="c)分类决策规则"></a>c)分类决策规则</h3><p>$k$ 近邻法中的分类决策规则往往是多数表决，即由输入实例的 $k$ 个邻近的训练实例中的多数类决定输入实例的类。</p><p>多数表决规则（majority voting rule）有如下解释：如果分类的损失函数为 0-1 损失函数，分类函数为</p><p>$$f : \mathbb{R}^n \to {c_1, c_2, \cdots, c_K}$$</p><p>那么误分类的概率是</p><p>$$P(Y \neq f(X)) &#x3D; 1 - P(Y &#x3D; f(X))$$</p><p>对给定的实例 $x \in \mathcal{X}$，其最近邻的 $k$ 个训练实例点构成集合 $N_k(x)$。如果涵盖 $N_k(x)$ 的区域的类别是 $c_j$，那么误分类率是</p><p>$$\frac{1}{k} \sum_{x_i \in N_k(x)} I(y_i \neq c_j) &#x3D; 1 - \frac{1}{k} \sum_{x_i \in N_k(x)} I(y_i &#x3D; c_j)$$</p><p>要使误分类率最小即经验风险最小，就要使<br>$$\sum_{x_i \in N_k(x)} I(y_i &#x3D; c_j)$$<br>最大，所以多数表决规则等价于经验风险最小化。</p><h1 id="3-kNN的实现：kd树"><a href="#3-kNN的实现：kd树" class="headerlink" title="3. kNN的实现：kd树"></a>3. kNN的实现：kd树</h1><h2 id="3-1-kd树介绍"><a href="#3-1-kd树介绍" class="headerlink" title="3.1 kd树介绍"></a>3.1 kd树介绍</h2><p>kd树(k-dimensional tree)是一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。kd树是二叉树，表示对k维空间的一个划分，其每个结点对应于k维空间划分中的一个超矩形区域。</p><p>kd树的构造目的是实现高效的最近邻搜索，特别是在k维空间中的数据点很多时，直接计算距离的方法效率低下。</p><h2 id="3-2-kd树的构造"><a href="#3-2-kd树的构造" class="headerlink" title="3.2 kd树的构造"></a>3.2 kd树的构造</h2><p>kd树的构造过程是一个递归的过程：</p><ol><li>在k维空间中选择一个坐标轴j进行切分（通常按轮流选择的规则）</li><li>在选定的坐标轴上，选择切分点，将数据集划分为两部分</li><li>对划分的两部分分别递归构建左右子树</li></ol><p>常用的切分方式是选择当前维度上的中位数作为切分点，这样可以保证构造出的kd树是平衡的。</p><p>构造算法的数学描述如下：</p><p>$$\text{BuildKdTree}(P, depth):$$</p><p>$$<br>\begin{cases}<br>\text{如果 } P \text{ 为空，返回 } \text{null}\<br>\text{axis} &#x3D; \text{depth} \bmod k\<br>\text{按 } \text{axis} \text{ 维度对 } P \text{ 中的点排序}\<br>\text{median} &#x3D; \text{在 } \text{axis} \text{ 维度上的中位数点}\<br>\text{将 } \text{median} \text{ 作为根节点}\<br>\text{root.left} &#x3D; \text{BuildKdTree}(P_{\text{left}}, \text{depth}+1)\<br>\text{root.right} &#x3D; \text{BuildKdTree}(P_{\text{right}}, \text{depth}+1)\<br>\text{返回 } \text{root}<br>\end{cases}<br>$$</p><p>其中，$P_{\text{left}}$ 是 $\text{axis}$ 维度上小于 $\text{median}$ 的点集，$P_{\text{right}}$ 是大于 $\text{median}$ 的点集。</p><h2 id="3-3-kd树的最近邻搜索"><a href="#3-3-kd树的最近邻搜索" class="headerlink" title="3.3 kd树的最近邻搜索"></a>3.3 kd树的最近邻搜索</h2><p>kd树最核心的操作是搜索给定点的最近邻。算法步骤如下：</p><ol><li>从根节点开始，递归地向下遍历树</li><li>在每个节点，将目标点与当前节点比较</li><li>根据比较结果选择一个子树优先遍历</li><li>回溯时检查另一子树是否可能包含更近的点</li><li>如果可能，遍历另一子树</li></ol><p>最近邻搜索的数学表达为：</p><p>$$\text{NearestNeighbor}(\text{node}, \text{target}, \text{best}):$$</p><p>$$<br>\begin{cases}<br>\text{如果 } \text{node} \text{ 为空，返回 } \text{best}\<br>d &#x3D; \text{Distance}(\text{target}, \text{node.point})\<br>\text{如果 } d &lt; \text{Distance}(\text{target}, \text{best}) \text{ 则 } \text{best} &#x3D; \text{node.point}\<br>\text{axis} &#x3D; \text{node} \text{ 的划分维度}\<br>\text{如果 } \text{target}[\text{axis}] &lt; \text{node.point}[\text{axis}]\<br>\quad \text{first} &#x3D; \text{node.left}\<br>\quad \text{second} &#x3D; \text{node.right}\<br>\text{否则}\<br>\quad \text{first} &#x3D; \text{node.right}\<br>\quad \text{second} &#x3D; \text{node.left}\<br>\text{best} &#x3D; \text{NearestNeighbor}(\text{first}, \text{target}, \text{best})\<br>\text{如果 } |\text{target}[\text{axis}] - \text{node.point}[\text{axis}]| &lt; \text{Distance}(\text{target}, \text{best})\<br>\quad \text{best} &#x3D; \text{NearestNeighbor}(\text{second}, \text{target}, \text{best})\<br>\text{返回 } \text{best}<br>\end{cases}<br>$$</p><h2 id="3-4-kd树的复杂度分析"><a href="#3-4-kd树的复杂度分析" class="headerlink" title="3.4 kd树的复杂度分析"></a>3.4 kd树的复杂度分析</h2><ul><li>构建kd树的时间复杂度：$O(n\log n)$，其中$n$是数据点的数量</li><li>平衡kd树的空间复杂度：$O(n)$</li><li>最近邻搜索的平均时间复杂度：$O(\log n)$</li><li>最近邻搜索的最坏情况时间复杂度：$O(n)$（当数据分布极不均匀时）</li></ul><p>kd树在低维空间（通常 $k&lt;20$ ）中表现良好，但在高维空间中由于”维度灾难”问题，其效率会急剧下降。在高维情况下，可能需要考虑其他数据结构如哈希或近似最近邻算法。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
