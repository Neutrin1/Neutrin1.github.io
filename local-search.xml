<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>感知机(Perceptron)</title>
    <link href="/2025/03/25/Perceptron/"/>
    <url>/2025/03/25/Perceptron/</url>
    
    <content type="html"><![CDATA[<h1 id="1概述"><a href="#1概述" class="headerlink" title="1概述"></a>1概述</h1><p>感知机是一种用于二分类的线性分类模型，输入为实例的特征向量，输出为实例的类别，取$+1$和$-1$二值。感知机对应于输入空间中将实例划分为正负两类的分离超平面，属于判别模型。感知机的目的是训练出将输入数据进行二分类的超平面；因此，可以导入基于误分类的损失函数，并利用梯度下降算法对损失函数进行极小化，以此得到感知机模型。</p><h1 id="2感知机-简洁版"><a href="#2感知机-简洁版" class="headerlink" title="2感知机(简洁版)"></a>2感知机(简洁版)</h1><h2 id="2-1模型"><a href="#2-1模型" class="headerlink" title="2.1模型"></a>2.1模型</h2><p>定义由输入空间到输出空间的函数：</p><p>$$f(x)&#x3D;sign(wx+b)$$</p><p>称感知机。其中，权重$w$和偏置$b$是感知机的参数，$sign$是符号函数。感知机是一种线性分类模型，属于判别模型。<br><img src="/image/Perceptron1.png"><br>由上可知，对于感知机，输出值无非不过两种情况：</p><p>$$wx+b&gt;0&#x2F;wx+b&lt;0$$</p><p>而我们要找的超平面为</p><p>$$wx+b&#x3D;0$$</p><p>注意，数据集必须要线性可分。</p><h2 id="2-2学习策略"><a href="#2-2学习策略" class="headerlink" title="2.2学习策略"></a>2.2学习策略</h2><h3 id="a）损失函数"><a href="#a）损失函数" class="headerlink" title="a）损失函数"></a>a）损失函数</h3><p>$$-\frac{1}{|w|} \sum_{x_i \in M} y_i (w \cdot x_i + b)$$</p><p>是所有误分类点到超平面$S$的总距离，其中</p><p>$$-\frac{1}{|w|}$$</p><p>为$w$的$L_2$范数，若不考虑，则损失函数的定义为：</p><p>$$L(w, b) &#x3D; -\sum_{x_i \in M} y_i (w \cdot x_i + b)$$</p><p>这是关于$w$,$b$的连续可导函数。</p><h3 id="b）学习算法"><a href="#b）学习算法" class="headerlink" title="b）学习算法"></a>b）学习算法</h3><p>获得感知机模型的过程本质上就是极小化损失函数的过程：</p><p>$$\min_{w, b} L(w, b) &#x3D; - \sum_{x_i \in M} y_i (w \cdot x_i + b)$$</p><p>假设误分类点集合是固定的，那么损失函数$L(w,b)$的梯度由：<br>$$\nabla_w L(w, b) &#x3D; - \sum_{x_i \in M} y_i x_i$$</p><p>$$\nabla_b L(w, b) &#x3D; - \sum_{x_i \in M} y_i$$<br>给出。</p><p>随机选取一个误分类点$(x_i,y_i)$，对$w$,$b$进行更新：</p><p>$$w \leftarrow w + \eta y_i x_i$$</p><p>$$b \leftarrow b + \eta y_i$$<br>其中$\eta$是学习率。</p><h1 id="3实现代码"><a href="#3实现代码" class="headerlink" title="3实现代码"></a>3实现代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/env python</span><br><span class="hljs-comment"># -*- encoding: utf-8 -*-</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">@File    :   感知机.ipynb</span><br><span class="hljs-string">@Time    :   2025/03/24 21:29:44</span><br><span class="hljs-string">@Author  :   Neutrin </span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># here put the import lib</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>np.random.seed(<span class="hljs-number">42</span>)  <br><br><span class="hljs-comment"># 生成样本点 100个负样本 100个正样本</span><br>n_samples_neg = <span class="hljs-number">100</span><br>X_neg = np.random.normal(loc=[-<span class="hljs-number">2</span>, -<span class="hljs-number">2</span>], scale=<span class="hljs-number">1.0</span>, size=(n_samples_neg, <span class="hljs-number">2</span>))<br>y_neg = np.zeros(n_samples_neg)<br><br>n_samples_pos = <span class="hljs-number">100</span><br>X_pos = np.random.normal(loc=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], scale=<span class="hljs-number">1.0</span>, size=(n_samples_pos, <span class="hljs-number">2</span>))<br>y_pos = np.ones(n_samples_pos)<br><br><span class="hljs-comment"># 合并样本点</span><br>X = np.vstack((X_neg, X_pos))<br>y = np.hstack((y_neg, y_pos))<br><br><span class="hljs-comment"># 可视化</span><br>plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">6</span>))<br>plt.scatter(X_neg[:, <span class="hljs-number">0</span>], X_neg[:, <span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;blue&#x27;</span>, marker=<span class="hljs-string">&#x27;o&#x27;</span>, label=<span class="hljs-string">&#x27;Class 0&#x27;</span>)<br>plt.scatter(X_pos[:, <span class="hljs-number">0</span>], X_pos[:, <span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;red&#x27;</span>, marker=<span class="hljs-string">&#x27;x&#x27;</span>, label=<span class="hljs-string">&#x27;Class 1&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Perceptron Training Data&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Feature 1&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Feature 2&#x27;</span>)<br>plt.legend()<br>plt.grid(<span class="hljs-literal">True</span>)<br>plt.show()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Dataset shape: X: <span class="hljs-subst">&#123;X.shape&#125;</span>, y: <span class="hljs-subst">&#123;y.shape&#125;</span>&quot;</span>)<br><span class="hljs-comment"># 感知机用于二分类问题，输出为+1或-1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">out</span>(<span class="hljs-params">x, w, b</span>):<br>    <span class="hljs-keyword">return</span> np.sign(np.dot(x, w) + b)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Perceptron</span>: <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, learning_rate=<span class="hljs-number">0.01</span>, max_iterations=<span class="hljs-number">1000</span></span>):  <span class="hljs-comment"># 学习率和最大迭代次数</span><br>        <span class="hljs-variable language_">self</span>.learning_rate = learning_rate<br>        <span class="hljs-variable language_">self</span>.max_iterations = max_iterations<br>        <span class="hljs-variable language_">self</span>.w = <span class="hljs-literal">None</span><br>        <span class="hljs-variable language_">self</span>.b = <span class="hljs-literal">None</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, X, y</span>):<br>        <span class="hljs-comment"># 初始化权重和偏置</span><br>        n_samples, n_features = X.shape  <span class="hljs-comment"># 样本数和特征数</span><br>        <span class="hljs-variable language_">self</span>.w = np.zeros(n_features)<br>        <span class="hljs-variable language_">self</span>.b = <span class="hljs-number">0</span><br>        <br>        <span class="hljs-comment"># 将标签0转为-1 (感知机标签通常为-1和+1)</span><br>        y_transformed = np.where(y == <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># where函数，满足条件输出1，不满足输出0</span><br>        <br>        <span class="hljs-comment"># 训练模型</span><br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-variable language_">self</span>.max_iterations):<br>            misclassified = <span class="hljs-number">0</span>               <span class="hljs-comment"># 错误分类的样本数</span><br>            <span class="hljs-keyword">for</span> idx, x_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(X):   <br>                y_i = y_transformed[idx]<br>                <span class="hljs-comment"># 如果预测错误，更新权重</span><br>                <span class="hljs-keyword">if</span> y_i * (np.dot(x_i, <span class="hljs-variable language_">self</span>.w) + <span class="hljs-variable language_">self</span>.b) &lt;= <span class="hljs-number">0</span>:<br>                    <span class="hljs-variable language_">self</span>.w += <span class="hljs-variable language_">self</span>.learning_rate * y_i * x_i<br>                    <span class="hljs-variable language_">self</span>.b += <span class="hljs-variable language_">self</span>.learning_rate * y_i<br>                    misclassified += <span class="hljs-number">1</span><br>            <span class="hljs-comment"># 如果没有错误分类，提前结束训练</span><br>            <span class="hljs-keyword">if</span> misclassified == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">break</span><br>                <br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-keyword">return</span> np.where(np.sign(np.dot(X, <span class="hljs-variable language_">self</span>.w) + <span class="hljs-variable language_">self</span>.b) == -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">score</span>(<span class="hljs-params">self, X, y</span>):<br>        y_pred = <span class="hljs-variable language_">self</span>.predict(X)<br>        <span class="hljs-keyword">return</span> np.mean(y_pred == y)<br>    <br>    <span class="hljs-comment"># 获取用于绘制决策边界的参数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decision_boundary</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.w, <span class="hljs-variable language_">self</span>.b<br><br><span class="hljs-comment"># 创建并训练感知机模型</span><br>perceptron = Perceptron(learning_rate=<span class="hljs-number">0.01</span>, max_iterations=<span class="hljs-number">1000</span>)<br>perceptron.fit(X, y)<br><br><span class="hljs-comment"># 评估模型</span><br>accuracy = perceptron.score(X, y)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Accuracy: <span class="hljs-subst">&#123;accuracy:<span class="hljs-number">.4</span>f&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 绘制决策边界</span><br>w, b = perceptron.decision_boundary()<br>x_min, x_max = X[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">min</span>() - <span class="hljs-number">1</span>, X[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">max</span>() + <span class="hljs-number">1</span><br>y_min, y_max = X[:, <span class="hljs-number">1</span>].<span class="hljs-built_in">min</span>() - <span class="hljs-number">1</span>, X[:, <span class="hljs-number">1</span>].<span class="hljs-built_in">max</span>() + <span class="hljs-number">1</span><br>xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="hljs-number">0.1</span>),<br>                     np.arange(y_min, y_max, <span class="hljs-number">0.1</span>))<br>Z = np.sign(np.dot(np.c_[xx.ravel(), yy.ravel()], w) + b).reshape(xx.shape)<br><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.contourf(xx, yy, Z, alpha=<span class="hljs-number">0.3</span>, cmap=plt.cm.coolwarm)<br>plt.scatter(X_neg[:, <span class="hljs-number">0</span>], X_neg[:, <span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;blue&#x27;</span>, marker=<span class="hljs-string">&#x27;o&#x27;</span>, label=<span class="hljs-string">&#x27;Class 0&#x27;</span>)<br>plt.scatter(X_pos[:, <span class="hljs-number">0</span>], X_pos[:, <span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;red&#x27;</span>, marker=<span class="hljs-string">&#x27;x&#x27;</span>, label=<span class="hljs-string">&#x27;Class 1&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Perceptron Decision Boundary&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Feature 1&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Feature 2&#x27;</span>)<br>plt.legend()<br>plt.grid(<span class="hljs-literal">True</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Machine-Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
